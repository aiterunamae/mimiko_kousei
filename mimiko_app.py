import streamlit as st
import json
import toml
import os
from pathlib import Path
from datetime import datetime
import pandas as pd
import io

# Google GenAI SDKã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import google.genai as genai
    from google.genai import types
    NEW_SDK = True
except ImportError:
    try:
        import google.generativeai as genai
        NEW_SDK = False
        st.warning("å¤ã„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚pip install google-genai ã§æ–°ã—ã„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«æ›´æ–°ã—ã¦ãã ã•ã„ã€‚")
    except ImportError:
        st.error("Google GenAI ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚pip install google-genai ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        st.stop()

# Vertex AIç”¨ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from google.auth import default
    from google.auth.transport.requests import Request
    from google.oauth2 import service_account
    VERTEX_AI_AVAILABLE = True
except ImportError:
    VERTEX_AI_AVAILABLE = False

# Load secrets
# Streamlit Cloudã®å ´åˆ
if hasattr(st, "secrets"):
    try:
        # æ–°ã—ã„å½¢å¼ã«å¯¾å¿œ
        vertex_ai_project_id = st.secrets["api"]["vertex_project"] if "api" in st.secrets and "vertex_project" in st.secrets["api"] else ""
        vertex_ai_location = st.secrets["api"]["vertex_location"] if "api" in st.secrets and "vertex_location" in st.secrets["api"] else "us-central1"
        default_model = st.secrets.get("default_model", "gemini-2.0-flash-exp")
        
        # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±
        gcp_service_account = dict(st.secrets["gcp_service_account"]) if "gcp_service_account" in st.secrets else None
    except Exception as e:
        st.error(f"Secretsã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        vertex_ai_project_id = ""
        vertex_ai_location = "us-central1"
        default_model = "gemini-2.0-flash-exp"
        gcp_service_account = None
else:
    # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã®å ´åˆ
    secrets_path = Path(__file__).parent / "secrets.toml"
    if secrets_path.exists():
        secrets = toml.load(secrets_path)
        api_config = secrets.get("api", {})
        vertex_ai_project_id = api_config.get("vertex_project", "")
        vertex_ai_location = api_config.get("vertex_location", "us-central1")
        default_model = secrets.get("default_model", "gemini-2.0-flash-exp")
        gcp_service_account = secrets.get("gcp_service_account", None)
    else:
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
        vertex_ai_project_id = os.environ.get("VERTEX_AI_PROJECT_ID", "")
        vertex_ai_location = os.environ.get("VERTEX_AI_LOCATION", "us-central1")
        default_model = os.environ.get("DEFAULT_MODEL", "gemini-2.0-flash-exp")
        gcp_service_account = None

# Vertex AI ãƒ¢ãƒ‡ãƒ«ã‚ªãƒ—ã‚·ãƒ§ãƒ³
vertex_model_options = [
    "gemini-2.0-flash-exp",
    "gemini-1.5-flash-002",
    "gemini-1.5-pro-002"
]

# Load correction prompts
def load_prompt(filename):
    prompt_path = Path(__file__).parent / filename
    with open(prompt_path, "r", encoding="utf-8") as f:
        return f.read()

# Load all prompts (ãƒ‘ã‚¿ãƒ¼ãƒ³é¡ä¼¼åº¦æ ¡æ­£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é™¤ã)
try:
    tonmana_prompt = load_prompt("ãƒˆãƒ³ãƒãƒŠæ ¡æ­£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ.txt")
    japanese_prompt = load_prompt("æ—¥æœ¬èªæ ¡æ­£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ.txt")
    logic_prompt = load_prompt("ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ.txt")
    comprehensive_prompt = load_prompt("ç·åˆæ ¡æ­£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ.txt")
except Exception as e:
    st.error(f"Error loading prompts: {e}")
    st.stop()

# Vertex AIè¨­å®šé–¢æ•°
def setup_vertex_ai(model_name, project_id=None, location=None, service_account=None):
    """Vertex AI ã‚’è¨­å®šã™ã‚‹"""
    try:
        if not VERTEX_AI_AVAILABLE:
            st.error("Vertex AI ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return None, None
            
        if not project_id:
            st.error("Project IDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return None, None
        
        # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼ã‚’ä½¿ç”¨
        if service_account:
            try:
                from google.oauth2 import service_account as sa
                credentials = sa.Credentials.from_service_account_info(
                    service_account,
                    scopes=['https://www.googleapis.com/auth/cloud-platform']
                )
            except Exception as e:
                st.error(f"ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
                credentials = None
        else:
            credentials = None
            
        if NEW_SDK:
            if credentials:
                # èªè¨¼æƒ…å ±ã‚’ä½¿ç”¨
                os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = ''  # Clear any existing
                client = genai.Client(
                    vertexai=True,
                    project=project_id,
                    location=location,
                    credentials=credentials
                )
            else:
                client = genai.Client(
                    vertexai=True,
                    project=project_id,
                    location=location
                )
        else:
            genai.configure(project=project_id, location=location)
            client = None
        return client, model_name
    except Exception as e:
        st.error(f"Vertex AI ã®è¨­å®šã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        import traceback
        st.error(traceback.format_exc())
        return None, None

# Function to call Gemini API  
def call_gemini(prompt, user_message, model_name, project_id=None, location=None, service_account=None):
    """Gemini APIã‚’å‘¼ã³å‡ºã™"""
    try:
        client, model = setup_vertex_ai(model_name, project_id, location, service_account)
        
        if client is None and model is None:
            return None
            
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ§‹ç¯‰
        full_message = f"{prompt}\n\n{user_message}"
        
        if NEW_SDK:
            if client:
                response = client.models.generate_content(
                    model=model,
                    contents=full_message,
                    config=types.GenerateContentConfig(
                        max_output_tokens=1000,
                        temperature=0.1,
                    )
                )
                return response.text
            else:
                st.error("ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return None
        else:
            model_obj = genai.GenerativeModel(model)
            response = model_obj.generate_content(
                full_message,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=1000,
                    temperature=0.1,
                )
            )
            return response.text
            
    except Exception as e:
        st.error(f"Gemini APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        st.error(traceback.format_exc())
        return None

# Function to parse JSON from Claude's response
def parse_json_response(response):
    try:
        # Find JSON in the response
        start_idx = response.find('{')
        end_idx = response.rfind('}') + 1
        if start_idx >= 0 and end_idx > start_idx:
            json_str = response[start_idx:end_idx]
            return json.loads(json_str)
        else:
            st.warning("Could not find JSON in the response")
            return None
    except Exception as e:
        st.error(f"Error parsing JSON: {e}")
        st.code(response)  # Display the raw response for debugging
        return None

# Main app
st.title("mimikoæ ¡æ­£ã‚·ã‚¹ãƒ†ãƒ ")

# Initialize variables with default values
project_id_input = vertex_ai_project_id
location_input = vertex_ai_location

# Project IDãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã®è­¦å‘Š
if not vertex_ai_project_id:
    st.warning("âš ï¸ Vertex AI Project IDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

# Settings section
with st.expander("âš™ï¸ è¨­å®š", expanded=not vertex_ai_project_id):
    col1, col2 = st.columns(2)
    
    with col1:
        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        selected_model = st.selectbox(
            "ğŸ¯ ãƒ¢ãƒ‡ãƒ«",
            vertex_model_options,
            index=0 if default_model not in vertex_model_options else vertex_model_options.index(default_model),
            key="selected_model"
        )
    
    with col2:
        project_id_input = st.text_input(
            "ğŸ“ Project ID",
            value=vertex_ai_project_id,
            help="Google Cloud ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
        )
        location_input = st.text_input(
            "ğŸŒ Location",
            value=vertex_ai_location,
            help="Vertex AI ã®ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æŒ‡å®šã—ã¦ãã ã•ã„"
        )

# Input section
st.header("å…¥åŠ›")

# å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰é¸æŠ
input_mode = st.radio(
    "å…¥åŠ›æ–¹æ³•ã‚’é¸æŠ",
    ["æ‰‹å‹•å…¥åŠ›", "CSVä¸€æ‹¬å‡¦ç†"],
    key="input_mode"
)

if input_mode == "æ‰‹å‹•å…¥åŠ›":
    user_question = st.text_area("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•", height=100)
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚«ãƒ†ã‚´ãƒªé¸æŠï¼ˆæœ€å¤§4ã¤ã¾ã§ï¼‰
    st.subheader("ä½¿ç”¨ã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚«ãƒ†ã‚´ãƒª")
    col1, col2 = st.columns(2)
    
    with col1:
        category1 = st.selectbox("ã‚«ãƒ†ã‚´ãƒª1", ["ãªã—", "ãƒã‚¦ã‚¹", "ã‚µã‚¤ãƒ³", "å¤©ä½“", "ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆ", "MPè»¸", "ã‚¿ãƒ­ãƒƒãƒˆ"], key="cat1")
        if category1 != "ãªã—":
            keyword1 = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", placeholder="ä¾‹: ç¬¬1ãƒã‚¦ã‚¹", key="kw1")
        else:
            keyword1 = ""
    
    with col2:
        category2 = st.selectbox("ã‚«ãƒ†ã‚´ãƒª2", ["ãªã—", "ãƒã‚¦ã‚¹", "ã‚µã‚¤ãƒ³", "å¤©ä½“", "ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆ", "MPè»¸", "ã‚¿ãƒ­ãƒƒãƒˆ"], key="cat2")
        if category2 != "ãªã—":
            keyword2 = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2", placeholder="ä¾‹: ç‰¡ç¾Šåº§", key="kw2")
        else:
            keyword2 = ""
    
    col3, col4 = st.columns(2)
    
    with col3:
        category3 = st.selectbox("ã‚«ãƒ†ã‚´ãƒª3", ["ãªã—", "ãƒã‚¦ã‚¹", "ã‚µã‚¤ãƒ³", "å¤©ä½“", "ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆ", "MPè»¸", "ã‚¿ãƒ­ãƒƒãƒˆ"], key="cat3")
        if category3 != "ãªã—":
            keyword3 = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰3", placeholder="ä¾‹: å¤ªé™½", key="kw3")
        else:
            keyword3 = ""
    
    with col4:
        category4 = st.selectbox("ã‚«ãƒ†ã‚´ãƒª4", ["ãªã—", "ãƒã‚¦ã‚¹", "ã‚µã‚¤ãƒ³", "å¤©ä½“", "ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆ", "MPè»¸", "ã‚¿ãƒ­ãƒƒãƒˆ"], key="cat4")
        if category4 != "ãªã—":
            keyword4 = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰4", placeholder="ä¾‹: ç«", key="kw4")
        else:
            keyword4 = ""
    
    ai_answer = st.text_area("AIå ã„å¸«ã®å›ç­”", height=150)
    
else:  # CSVä¸€æ‹¬å‡¦ç†ãƒ¢ãƒ¼ãƒ‰
    st.info("ç”Ÿæˆã‚¢ãƒ—ãƒªã§å‡ºåŠ›ã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    
    uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", type=['csv'])
    
    if uploaded_file is not None:
        try:
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
            
            # å¿…è¦ãªåˆ—ã®å­˜åœ¨ç¢ºèª
            required_columns = ["id", "è³ªå•", "å›ç­”"]
            if not all(col in df.columns for col in required_columns):
                st.error(f"å¿…é ˆåˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {required_columns}")
            else:
                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ—ã®æ¤œå‡ºï¼ˆå‹•çš„ã«å¯¾å¿œï¼‰
                keyword_columns = []
                for col in df.columns:
                    # ã‚«ãƒ†ã‚´ãƒªåã§çµ‚ã‚ã‚‹åˆ—ã‚’æ¤œå‡ºï¼ˆä¾‹: ãƒã‚¦ã‚¹1, ã‚µã‚¤ãƒ³2, ãªã©ï¼‰
                    if any(col.endswith(str(i)) for i in range(1, 5)):
                        for cat in ["ãƒã‚¦ã‚¹", "ã‚µã‚¤ãƒ³", "å¤©ä½“", "ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆ", "MPè»¸", "ã‚¿ãƒ­ãƒƒãƒˆ"]:
                            if col.startswith(cat):
                                keyword_columns.append(col)
                                break
                
                st.success(f"âœ… {len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                st.write(f"æ¤œå‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ—: {keyword_columns}")
                
                # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
                with st.expander("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", expanded=False):
                    st.dataframe(df.head())
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                if 'csv_data' not in st.session_state:
                    st.session_state.csv_data = df
                    st.session_state.keyword_columns = keyword_columns
                
        except Exception as e:
            st.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

# Initialize session state
if 'corrections' not in st.session_state:
    st.session_state.corrections = {}
if 'tonmana_problems' not in st.session_state:
    st.session_state.tonmana_problems = []
if 'japanese_improvements' not in st.session_state:
    st.session_state.japanese_improvements = []
if 'logic_improvements' not in st.session_state:
    st.session_state.logic_improvements = []
if 'correction_done' not in st.session_state:
    st.session_state.correction_done = False
if 'user_input' not in st.session_state:
    st.session_state.user_input = {"question": "", "keywords": [], "answer": ""}

# Process button
if input_mode == "æ‰‹å‹•å…¥åŠ›":
    if st.button("æ ¡æ­£ã‚’å®Ÿè¡Œ") or st.session_state.correction_done:
        if not user_question or not ai_answer:
            st.error("è³ªå•ã¨å›ç­”ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        else:
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æƒ…å ±ã®æ•´ç†
            keywords = []
            if category1 != "ãªã—" and keyword1:
                keywords.append(f"{category1}: {keyword1}")
            if category2 != "ãªã—" and keyword2:
                keywords.append(f"{category2}: {keyword2}")
            if category3 != "ãªã—" and keyword3:
                keywords.append(f"{category3}: {keyword3}")
            if category4 != "ãªã—" and keyword4:
                keywords.append(f"{category4}: {keyword4}")
            
            # Save user input to session state
            st.session_state.user_input = {
                "question": user_question,
                "keywords": keywords,
                "answer": ai_answer
            }
            
            # Set correction_done flag to true
            st.session_state.correction_done = True
            
            # è¨­å®šã®æº–å‚™
            current_project_id = project_id_input
            current_location = location_input
            current_service_account = gcp_service_account

            # Only call APIs if not already done
        if 'tonmana_result' not in st.session_state:
            with st.spinner("ãƒˆãƒ³ãƒãƒŠæ ¡æ­£ä¸­..."):
                # 1. ãƒˆãƒ³ãƒãƒŠæ ¡æ­£
                tonmana_message = f"""##QUESTION##
{user_question}

##KEYWORDS##
{', '.join(keywords) if keywords else 'ãªã—'}

##ANSWER_CAND##
{ai_answer}
"""
                tonmana_result = call_gemini(
                    tonmana_prompt, 
                    tonmana_message,
                    selected_model,
                    current_project_id,
                    current_location,
                    current_service_account
                )
                if tonmana_result:
                    tonmana_json = parse_json_response(tonmana_result)
                    if tonmana_json:
                        st.session_state.tonmana_result = tonmana_result
                        st.session_state.tonmana_json = tonmana_json
                        
                        # Store in session state
                        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã¯improvementsã¨ã„ã†åå‰ã ãŒã€å†…éƒ¨çš„ã«problemsã¨ã—ã¦æ‰±ã†
                        problems = tonmana_json.get('improvements', tonmana_json.get('problems', []))
                        st.session_state.corrections["tonmana"] = {
                            "score": tonmana_json.get('style_score', 'N/A'),
                            "comment": tonmana_json.get('comment', 'N/A'),
                            "problems": problems
                        }
        
        if 'japanese_result' not in st.session_state:
            with st.spinner("æ—¥æœ¬èªæ ¡æ­£ä¸­..."):
                # 2. æ—¥æœ¬èªæ ¡æ­£
                japanese_message = ai_answer
                japanese_result = call_gemini(
                    japanese_prompt,
                    japanese_message,
                    selected_model,
                    current_project_id,
                    current_location,
                    current_service_account
                )
                if japanese_result:
                    japanese_json = parse_json_response(japanese_result)
                    if japanese_json:
                        st.session_state.japanese_result = japanese_result
                        st.session_state.japanese_json = japanese_json
                        
                        # Store in session state
                        st.session_state.corrections["japanese"] = {
                            "score": japanese_json.get('score', 'N/A'),
                            "improvements": japanese_json.get('improvements', [])
                        }
        
        if 'logic_result' not in st.session_state and logic_prompt.strip():
            with st.spinner("ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£ä¸­..."):
                # 3. ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£
                logic_message = f"""è³ªå•: {user_question}
ä½¿ç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(keywords) if keywords else 'ãªã—'}
å›ç­”: {ai_answer}
"""
                logic_result = call_gemini(
                    logic_prompt,
                    logic_message,
                    selected_model,
                    current_project_id,
                    current_location,
                    current_service_account
                )
                if logic_result:
                    logic_json = parse_json_response(logic_result)
                    if logic_json:
                        st.session_state.logic_result = logic_result
                        st.session_state.logic_json = logic_json
                        
                        # Store in session state
                        st.session_state.corrections["logic"] = {
                            "score": logic_json.get('score', 'N/A'),
                            "improvements": logic_json.get('improvements', [])
                        }
        
        # Calculate total score
        total_score = 0
        max_score = 15
        valid_scores = 0
        
        for correction_type in ["tonmana", "japanese", "logic"]:
            if correction_type in st.session_state.corrections:
                score = st.session_state.corrections[correction_type]["score"]
                if isinstance(score, (int, float)) and score != 'N/A':
                    total_score += score
                    valid_scores += 1
        
        # Display total score
        if valid_scores > 0:
            st.header(f"ç·åˆã‚¹ã‚³ã‚¢: {total_score}/{max_score}ç‚¹")
        
        # Display results
        # 1. ãƒˆãƒ³ãƒãƒŠæ ¡æ­£çµæœ
        if 'tonmana_json' in st.session_state:
            st.subheader("ãƒˆãƒ³ãƒãƒŠæ ¡æ­£çµæœ")
            tonmana_json = st.session_state.tonmana_json
            st.write(f"ã‚¹ã‚³ã‚¢: {tonmana_json.get('style_score', 'N/A')}/5")
            st.write(f"ã‚³ãƒ¡ãƒ³ãƒˆ: {tonmana_json.get('comment', 'N/A')}")
            
            problems = tonmana_json.get('improvements', tonmana_json.get('problems', []))
            if problems:
                st.write("æ”¹å–„ç‚¹:")
                for i, problem in enumerate(problems):
                    # Create a unique key for each checkbox
                    checkbox_key = f"tonmana_cb_{i}"
                    
                    # Check if the problem is in the selected problems list
                    is_selected = problem in st.session_state.tonmana_problems
                    
                    # Display checkbox
                    checked = st.checkbox(problem, key=checkbox_key, value=is_selected)
                    
                    # Update selected problems list based on checkbox state
                    if checked and problem not in st.session_state.tonmana_problems:
                        st.session_state.tonmana_problems.append(problem)
                    elif not checked and problem in st.session_state.tonmana_problems:
                        st.session_state.tonmana_problems.remove(problem)
            else:
                st.write("æ”¹å–„ç‚¹ã¯ã‚ã‚Šã¾ã›ã‚“")
        
        # 2. æ—¥æœ¬èªæ ¡æ­£çµæœ
        if 'japanese_json' in st.session_state:
            st.subheader("æ—¥æœ¬èªæ ¡æ­£çµæœ")
            japanese_json = st.session_state.japanese_json
            st.write(f"ã‚¹ã‚³ã‚¢: {japanese_json.get('score', 'N/A')}/5")
            
            improvements = japanese_json.get('improvements', [])
            if improvements:
                st.write("æ”¹å–„ç‚¹:")
                for i, improvement in enumerate(improvements):
                    # Create a unique key for each checkbox
                    checkbox_key = f"japanese_cb_{i}"
                    
                    # Check if the improvement is in the selected improvements list
                    is_selected = improvement in st.session_state.japanese_improvements
                    
                    # Display checkbox
                    checked = st.checkbox(improvement, key=checkbox_key, value=is_selected)
                    
                    # Update selected improvements list based on checkbox state
                    if checked and improvement not in st.session_state.japanese_improvements:
                        st.session_state.japanese_improvements.append(improvement)
                    elif not checked and improvement in st.session_state.japanese_improvements:
                        st.session_state.japanese_improvements.remove(improvement)
            else:
                st.write("æ”¹å–„ç‚¹ã¯ã‚ã‚Šã¾ã›ã‚“")
        
        # 3. ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£çµæœ
        if 'logic_json' in st.session_state:
            st.subheader("ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£çµæœ")
            logic_json = st.session_state.logic_json
            st.write(f"ã‚¹ã‚³ã‚¢: {logic_json.get('score', 'N/A')}/5")
            
            improvements = logic_json.get('improvements', [])
            if improvements:
                st.write("æ”¹å–„ç‚¹:")
                for i, improvement in enumerate(improvements):
                    # Create a unique key for each checkbox
                    checkbox_key = f"logic_cb_{i}"
                    
                    # Check if the improvement is in the selected improvements list
                    is_selected = improvement in st.session_state.logic_improvements
                    
                    # Display checkbox
                    checked = st.checkbox(improvement, key=checkbox_key, value=is_selected)
                    
                    # Update selected improvements list based on checkbox state
                    if checked and improvement not in st.session_state.logic_improvements:
                        st.session_state.logic_improvements.append(improvement)
                    elif not checked and improvement in st.session_state.logic_improvements:
                        st.session_state.logic_improvements.remove(improvement)
            else:
                st.write("æ”¹å–„ç‚¹ã¯ã‚ã‚Šã¾ã›ã‚“")
        elif logic_prompt.strip():
            st.warning("ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒç©ºã§ã™ã€‚ã“ã®æ ¡æ­£ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")
        
        # Show button to proceed to comprehensive correction
        st.session_state.show_comprehensive_button = True

# Reset button
if st.button("ãƒªã‚»ãƒƒãƒˆ"):
    # Clear session state
    for key in list(st.session_state.keys()):
        del st.session_state[key]
    # Rerun the app
    st.rerun()

# Comprehensive correction button
if st.session_state.get("show_comprehensive_button", False):
    st.header("ç·åˆæ ¡æ­£")
    if st.button("é¸æŠã—ãŸæ”¹å–„ç‚¹ã§ç·åˆæ ¡æ­£ã‚’å®Ÿè¡Œ") or 'comprehensive_result' in st.session_state:
        if 'comprehensive_result' not in st.session_state:
            with st.spinner("ç·åˆæ ¡æ­£ä¸­..."):
                # è¨­å®šã®æº–å‚™ï¼ˆcomprehensive correctionç”¨ï¼‰
                current_project_id = project_id_input
                current_location = location_input
                current_service_account = gcp_service_account
                # Prepare selected improvements
                selected_improvements = {
                    "ãƒˆãƒ³ãƒãƒŠæ ¡æ­£": st.session_state.get("tonmana_problems", []),
                    "æ—¥æœ¬èªæ ¡æ­£": st.session_state.get("japanese_improvements", []),
                    "ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£": st.session_state.get("logic_improvements", [])
                }
                
                # Prepare scores
                scores = {}
                if "tonmana" in st.session_state.corrections:
                    scores["ãƒˆãƒ³ãƒãƒŠæ ¡æ­£"] = st.session_state.corrections["tonmana"]["score"]
                if "japanese" in st.session_state.corrections:
                    scores["æ—¥æœ¬èªæ ¡æ­£"] = st.session_state.corrections["japanese"]["score"]
                if "logic" in st.session_state.corrections:
                    scores["ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£"] = st.session_state.corrections["logic"]["score"]
                
                # Create message for comprehensive correction
                comprehensive_message = f"""AIå ã„å¸«ã®å›ç­”:
{st.session_state.user_input["answer"]}

ä½¿ç”¨ã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:
{', '.join(st.session_state.user_input["keywords"]) if st.session_state.user_input["keywords"] else 'ãªã—'}

å„æ ¡æ­£AIã®æ¡ç‚¹çµæœ:
"""
                for correction_type, score in scores.items():
                    comprehensive_message += f"{correction_type}: {score}/5\n"
                
                comprehensive_message += "\né¸æŠã•ã‚ŒãŸæ”¹å–„ç‚¹:\n"
                for correction_type, improvements in selected_improvements.items():
                    if improvements:
                        comprehensive_message += f"\n{correction_type}:\n"
                        for i, improvement in enumerate(improvements):
                            comprehensive_message += f"{i+1}. {improvement}\n"
                
                # Call Gemini for comprehensive correction
                comprehensive_result = call_gemini(
                    comprehensive_prompt,
                    comprehensive_message,
                    selected_model,
                    current_project_id,
                    current_location,
                    current_service_account
                )
                if comprehensive_result:
                    # Save the result to session state
                    st.session_state.comprehensive_result = comprehensive_result
        
        # Display comprehensive correction result
        if 'comprehensive_result' in st.session_state:
            st.subheader("ç·åˆæ ¡æ­£çµæœ")
            st.write(st.session_state.comprehensive_result)

# CSVä¸€æ‹¬å‡¦ç†ãƒ¢ãƒ¼ãƒ‰
elif input_mode == "CSVä¸€æ‹¬å‡¦ç†" and 'csv_data' in st.session_state:
    if st.button("ä¸€æ‹¬æ ¡æ­£ã‚’å®Ÿè¡Œ"):
        df = st.session_state.csv_data
        keyword_columns = st.session_state.keyword_columns
        
        # çµæœã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®åˆ—ã‚’è¿½åŠ 
        df['ãƒˆãƒ³ãƒãƒŠã‚¹ã‚³ã‚¢'] = 0
        df['æ—¥æœ¬èªã‚¹ã‚³ã‚¢'] = 0
        df['ãƒ­ã‚¸ãƒƒã‚¯ã‚¹ã‚³ã‚¢'] = 0
        df['ç·åˆã‚¹ã‚³ã‚¢'] = 0
        df['æ”¹å–„ç‚¹'] = ""
        df['ç·åˆæ ¡æ­£çµæœ'] = ""
        
        # è¨­å®šã®æº–å‚™
        current_project_id = project_id_input
        current_location = location_input
        current_service_account = gcp_service_account
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # å„è¡Œã‚’å‡¦ç†
        for index, row in df.iterrows():
            status_text.text(f"å‡¦ç†ä¸­: {index + 1}/{len(df)}")
            
            # è³ªå•ã¨å›ç­”ã‚’å–å¾—
            current_question = row['è³ªå•']
            current_answer = row['å›ç­”']
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ•´ç†
            keywords = []
            for col in keyword_columns:
                if pd.notna(row[col]):
                    # ã‚«ãƒ†ã‚´ãƒªåã‚’æŠ½å‡ºï¼ˆä¾‹: "ãƒã‚¦ã‚¹1" -> "ãƒã‚¦ã‚¹"ï¼‰
                    category = ''.join([c for c in col if not c.isdigit()])
                    keywords.append(f"{category}: {row[col]}")
            
            # 1. ãƒˆãƒ³ãƒãƒŠæ ¡æ­£
            tonmana_message = f"""##QUESTION##
{current_question}

##KEYWORDS##
{', '.join(keywords) if keywords else 'ãªã—'}

##ANSWER_CAND##
{current_answer}
"""
            tonmana_result = call_gemini(
                tonmana_prompt, 
                tonmana_message,
                selected_model,
                current_project_id,
                current_location,
                current_service_account
            )
            
            tonmana_json = parse_json_response(tonmana_result) if tonmana_result else None
            if tonmana_json:
                df.at[index, 'ãƒˆãƒ³ãƒãƒŠã‚¹ã‚³ã‚¢'] = tonmana_json.get('style_score', 0)
                problems = tonmana_json.get('improvements', tonmana_json.get('problems', []))
                if problems:
                    df.at[index, 'æ”¹å–„ç‚¹'] += f"ã€ãƒˆãƒ³ãƒãƒŠã€‘{', '.join(problems)}\n"
            
            # 2. æ—¥æœ¬èªæ ¡æ­£
            japanese_result = call_gemini(
                japanese_prompt,
                current_answer,
                selected_model,
                current_project_id,
                current_location,
                current_service_account
            )
            
            japanese_json = parse_json_response(japanese_result) if japanese_result else None
            if japanese_json:
                df.at[index, 'æ—¥æœ¬èªã‚¹ã‚³ã‚¢'] = japanese_json.get('score', 0)
                improvements = japanese_json.get('improvements', [])
                if improvements:
                    df.at[index, 'æ”¹å–„ç‚¹'] += f"ã€æ—¥æœ¬èªã€‘{', '.join(improvements)}\n"
            
            # 3. ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£
            logic_message = f"""è³ªå•: {current_question}
ä½¿ç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(keywords) if keywords else 'ãªã—'}
å›ç­”: {current_answer}
"""
            logic_result = call_gemini(
                logic_prompt,
                logic_message,
                selected_model,
                current_project_id,
                current_location,
                current_service_account
            )
            
            logic_json = parse_json_response(logic_result) if logic_result else None
            if logic_json:
                df.at[index, 'ãƒ­ã‚¸ãƒƒã‚¯ã‚¹ã‚³ã‚¢'] = logic_json.get('score', 0)
                improvements = logic_json.get('improvements', [])
                if improvements:
                    df.at[index, 'æ”¹å–„ç‚¹'] += f"ã€ãƒ­ã‚¸ãƒƒã‚¯ã€‘{', '.join(improvements)}\n"
            
            # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
            total_score = df.at[index, 'ãƒˆãƒ³ãƒãƒŠã‚¹ã‚³ã‚¢'] + df.at[index, 'æ—¥æœ¬èªã‚¹ã‚³ã‚¢'] + df.at[index, 'ãƒ­ã‚¸ãƒƒã‚¯ã‚¹ã‚³ã‚¢']
            df.at[index, 'ç·åˆã‚¹ã‚³ã‚¢'] = total_score
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°
            progress_bar.progress((index + 1) / len(df))
        
        status_text.text("å‡¦ç†å®Œäº†!")
        
        # çµæœè¡¨ç¤º
        st.subheader("æ ¡æ­£çµæœã‚µãƒãƒªãƒ¼")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            avg_tonmana = df['ãƒˆãƒ³ãƒãƒŠã‚¹ã‚³ã‚¢'].mean()
            st.metric("å¹³å‡ãƒˆãƒ³ãƒãƒŠã‚¹ã‚³ã‚¢", f"{avg_tonmana:.2f}/5")
        
        with col2:
            avg_japanese = df['æ—¥æœ¬èªã‚¹ã‚³ã‚¢'].mean()
            st.metric("å¹³å‡æ—¥æœ¬èªã‚¹ã‚³ã‚¢", f"{avg_japanese:.2f}/5")
        
        with col3:
            avg_logic = df['ãƒ­ã‚¸ãƒƒã‚¯ã‚¹ã‚³ã‚¢'].mean()
            st.metric("å¹³å‡ãƒ­ã‚¸ãƒƒã‚¯ã‚¹ã‚³ã‚¢", f"{avg_logic:.2f}/5")
        
        with col4:
            avg_total = df['ç·åˆã‚¹ã‚³ã‚¢'].mean()
            st.metric("å¹³å‡ç·åˆã‚¹ã‚³ã‚¢", f"{avg_total:.2f}/15")
        
        # çµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        with st.expander("çµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", expanded=True):
            st.dataframe(df[['id', 'è³ªå•', 'ãƒˆãƒ³ãƒãƒŠã‚¹ã‚³ã‚¢', 'æ—¥æœ¬èªã‚¹ã‚³ã‚¢', 'ãƒ­ã‚¸ãƒƒã‚¯ã‚¹ã‚³ã‚¢', 'ç·åˆã‚¹ã‚³ã‚¢', 'æ”¹å–„ç‚¹']].head(10))
        
        # CSVå‡ºåŠ›
        output_buffer = io.StringIO()
        df.to_csv(output_buffer, index=False, encoding='utf-8-sig')
        
        st.download_button(
            label="ğŸ“¥ æ ¡æ­£çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=output_buffer.getvalue(),
            file_name=f"mimiko_correction_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )