import streamlit as st
import json
import toml
import os
from pathlib import Path
from datetime import datetime
import pandas as pd
import io

# Google GenAI SDKã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import google.genai as genai
    from google.genai import types
    try:
        from google.genai.types import GenerateContentConfig, ThinkingConfig
        HAS_THINKING_CONFIG = True
    except ImportError:
        # å¤ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®å ´åˆ
        HAS_THINKING_CONFIG = False
    NEW_SDK = True
except ImportError:
    try:
        import google.generativeai as genai
        NEW_SDK = False
        HAS_THINKING_CONFIG = False
        st.warning("å¤ã„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚pip install google-genai ã§æ–°ã—ã„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«æ›´æ–°ã—ã¦ãã ã•ã„ã€‚")
    except ImportError:
        st.error("Google GenAI ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚pip install google-genai ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        st.stop()

# Vertex AIç”¨ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from google.auth import default
    from google.auth.transport.requests import Request
    from google.oauth2 import service_account
    VERTEX_AI_AVAILABLE = True
except ImportError:
    VERTEX_AI_AVAILABLE = False

# Load secrets
# Streamlit Cloudã®å ´åˆ
if hasattr(st, "secrets"):
    try:
        # æ–°ã—ã„å½¢å¼ã«å¯¾å¿œ
        vertex_ai_project_id = st.secrets["api"]["vertex_project"] if "api" in st.secrets and "vertex_project" in st.secrets["api"] else ""
        vertex_ai_location = st.secrets["api"]["vertex_location"] if "api" in st.secrets and "vertex_location" in st.secrets["api"] else "us-central1"
        default_model = st.secrets.get("default_model", "gemini-2.0-flash")
        
        # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±
        gcp_service_account = dict(st.secrets["gcp_service_account"]) if "gcp_service_account" in st.secrets else None
    except Exception as e:
        st.error(f"Secretsã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        vertex_ai_project_id = ""
        vertex_ai_location = "us-central1"
        default_model = "gemini-2.0-flash"
        gcp_service_account = None
else:
    # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã®å ´åˆ
    secrets_path = Path(__file__).parent / "secrets.toml"
    if secrets_path.exists():
        secrets = toml.load(secrets_path)
        api_config = secrets.get("api", {})
        vertex_ai_project_id = api_config.get("vertex_project", "")
        vertex_ai_location = api_config.get("vertex_location", "us-central1")
        default_model = secrets.get("default_model", "gemini-2.0-flash")
        gcp_service_account = secrets.get("gcp_service_account", None)
    else:
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
        vertex_ai_project_id = os.environ.get("VERTEX_AI_PROJECT_ID", "")
        vertex_ai_location = os.environ.get("VERTEX_AI_LOCATION", "us-central1")
        default_model = os.environ.get("DEFAULT_MODEL", "gemini-2.0-flash")
        gcp_service_account = None

# Vertex AI ãƒ¢ãƒ‡ãƒ«ã‚ªãƒ—ã‚·ãƒ§ãƒ³
vertex_model_options = [
    "gemini-2.0-flash",
    "gemini-2.5-flash",
    "gemini-2.5-pro"
]

# Load correction prompts
def load_prompt(filename):
    prompt_path = Path(__file__).parent / filename
    with open(prompt_path, "r", encoding="utf-8") as f:
        return f.read()

# Load keyword CSV files
def load_keyword_csv(category):
    """ã‚«ãƒ†ã‚´ãƒªã«å¿œã˜ãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰CSVã‚’èª­ã¿è¾¼ã‚€"""
    keyword_files = {
        "ãƒã‚¦ã‚¹": "ãƒã‚¦ã‚¹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰.csv",
        "ã‚µã‚¤ãƒ³": "ã‚µã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰.csv",
        "å¤©ä½“": "å¤©ä½“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰.csv",
        "ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆ": "ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰.csv",
        "MPè»¸": "MPè»¸ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰.csv",
        "ã‚¿ãƒ­ãƒƒãƒˆ": "ã‚¿ãƒ­ãƒƒãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰.csv"
    }
    
    if category not in keyword_files:
        return None
    
    try:
        csv_path = Path(__file__).parent / keyword_files[category]
        df = pd.read_csv(csv_path, encoding='utf-8-sig')
        return df
    except Exception as e:
        st.warning(f"{category}ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

# Get keyword details from CSV
def normalize_numbers(text):
    """å…¨è§’æ•°å­—ã‚’åŠè§’æ•°å­—ã«å¤‰æ›"""
    if not isinstance(text, str):
        return text
    # å…¨è§’æ•°å­—ã‚’åŠè§’æ•°å­—ã«å¤‰æ›
    trans_table = str.maketrans('ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™', '0123456789')
    return text.translate(trans_table)

def get_keyword_details(keywords_list):
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã‹ã‚‰è©³ç´°æƒ…å ±ã‚’å–å¾—"""
    keyword_details = []
    
    for keyword_str in keywords_list:
        # "ã‚«ãƒ†ã‚´ãƒª: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰" ã®å½¢å¼ã‹ã‚‰åˆ†è§£
        if ": " in keyword_str:
            category, keyword = keyword_str.split(": ", 1)
            
            # ã‚«ãƒ†ã‚´ãƒªã«å¿œã˜ãŸCSVã‚’èª­ã¿è¾¼ã¿
            df = load_keyword_csv(category)
            if df is not None:
                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ä¸€è‡´ã™ã‚‹è¡Œã‚’æ¤œç´¢
                # æœ€åˆã®åˆ—ï¼ˆåç§°åˆ—ï¼‰ã§æ¤œç´¢
                name_col = df.columns[0]
                
                # æ•°å­—ã‚’æ­£è¦åŒ–ã—ã¦æ¤œç´¢
                normalized_keyword = normalize_numbers(keyword)
                
                # CSVå´ã®æ•°å­—ã‚‚æ­£è¦åŒ–ã—ã¦æ¯”è¼ƒ
                df_normalized = df.copy()
                df_normalized[name_col] = df_normalized[name_col].apply(normalize_numbers)
                
                # å®Œå…¨ä¸€è‡´ã§æ¤œç´¢
                matching_rows = df_normalized[df_normalized[name_col] == normalized_keyword]
                
                # å®Œå…¨ä¸€è‡´ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€ã€Œç¬¬ã€ã‚’å«ã‚€/å«ã¾ãªã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚‚è©¦ã™
                if matching_rows.empty and category == "ãƒã‚¦ã‚¹":
                    if normalized_keyword.startswith("ç¬¬"):
                        # ã€Œç¬¬ã€ã‚’é™¤ã„ã¦æ¤œç´¢
                        alt_keyword = normalized_keyword[1:]
                        matching_rows = df_normalized[df_normalized[name_col] == alt_keyword]
                    else:
                        # ã€Œç¬¬ã€ã‚’è¿½åŠ ã—ã¦æ¤œç´¢
                        alt_keyword = "ç¬¬" + normalized_keyword
                        matching_rows = df_normalized[df_normalized[name_col] == alt_keyword]
                
                if not matching_rows.empty:
                    # æœ€åˆã®ä¸€è‡´è¡Œã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
                    matched_idx = matching_rows.index[0]
                    # å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰è¡Œã‚’å–å¾—
                    row = df.iloc[matched_idx]
                    
                    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®è©³ç´°æƒ…å ±ã‚’è¾æ›¸å½¢å¼ã§ä¿å­˜
                    detail = {
                        "ã‚«ãƒ†ã‚´ãƒª": category,
                        "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": keyword,
                        "CSVãƒ•ã‚¡ã‚¤ãƒ«": f"{category}ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰.csv",
                        "æ¤œç´¢åˆ—": name_col,
                        "ä¸€è‡´": "â—‹",
                        "æ­£è¦åŒ–å¾Œ": normalized_keyword
                    }
                    
                    # ä»–ã®åˆ—ã®æƒ…å ±ã‚‚è¿½åŠ 
                    for col in df.columns[1:]:
                        if pd.notna(row[col]):
                            detail[col] = row[col]
                    
                    keyword_details.append(detail)
                else:
                    # ä¸€è‡´ã—ãªã„å ´åˆã¯åŸºæœ¬æƒ…å ±ã®ã¿
                    keyword_details.append({
                        "ã‚«ãƒ†ã‚´ãƒª": category,
                        "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": keyword,
                        "CSVãƒ•ã‚¡ã‚¤ãƒ«": f"{category}ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰.csv",
                        "æ¤œç´¢åˆ—": name_col,
                        "ä¸€è‡´": "Ã—",
                        "æ­£è¦åŒ–å¾Œ": normalized_keyword,
                        "æ³¨æ„": "è©³ç´°æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
                    })
            else:
                # CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã¿è¾¼ã‚ãªã„å ´åˆ
                keyword_details.append({
                    "ã‚«ãƒ†ã‚´ãƒª": category,
                    "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": keyword,
                    "æ³¨æ„": "CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ"
                })
    
    return keyword_details

# Load all prompts (ãƒ‘ã‚¿ãƒ¼ãƒ³é¡ä¼¼åº¦æ ¡æ­£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é™¤ã)
try:
    tonmana_prompt = load_prompt("ãƒˆãƒ³ãƒãƒŠæ ¡æ­£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ.txt")
    japanese_prompt = load_prompt("æ—¥æœ¬èªæ ¡æ­£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ.txt")
    logic_prompt = load_prompt("ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ.txt")
    comprehensive_prompt = load_prompt("ç·åˆæ ¡æ­£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ.txt")
except Exception as e:
    st.error(f"Error loading prompts: {e}")
    st.stop()

# Vertex AIè¨­å®šé–¢æ•°
def setup_vertex_ai(model_name, project_id=None, location=None, service_account=None):
    """Vertex AI ã‚’è¨­å®šã™ã‚‹"""
    try:
        if not VERTEX_AI_AVAILABLE:
            st.error("Vertex AI ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return None, None
            
        if not project_id:
            st.error("Project IDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return None, None
        
        # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼ã‚’ä½¿ç”¨
        if service_account:
            try:
                from google.oauth2 import service_account as sa
                credentials = sa.Credentials.from_service_account_info(
                    service_account,
                    scopes=['https://www.googleapis.com/auth/cloud-platform']
                )
            except Exception as e:
                st.error(f"ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
                credentials = None
        else:
            credentials = None
            
        if NEW_SDK:
            if credentials:
                # èªè¨¼æƒ…å ±ã‚’ä½¿ç”¨
                os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = ''  # Clear any existing
                client = genai.Client(
                    vertexai=True,
                    project=project_id,
                    location=location,
                    credentials=credentials
                )
            else:
                client = genai.Client(
                    vertexai=True,
                    project=project_id,
                    location=location
                )
        else:
            genai.configure(project=project_id, location=location)
            client = None
        return client, model_name
    except Exception as e:
        st.error(f"Vertex AI ã®è¨­å®šã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        import traceback
        st.error(traceback.format_exc())
        return None, None

# Function to call Gemini API  
def call_gemini(prompt, user_message, model_name, project_id=None, location=None, service_account=None, max_tokens=2000, thinking_budget=1024):
    """Gemini APIã‚’å‘¼ã³å‡ºã™"""
    try:
        client, model = setup_vertex_ai(model_name, project_id, location, service_account)
        
        if client is None and model is None:
            return None
            
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ§‹ç¯‰
        full_message = f"{prompt}\n\n{user_message}"
        
        if NEW_SDK:
            if client:
                # GenerateContentConfigãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
                if HAS_THINKING_CONFIG and "2.5" in model:
                    # Gemini 2.5ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã€ThinkingConfigã‚’ä½¿ç”¨å¯èƒ½
                    config = GenerateContentConfig(
                        max_output_tokens=max_tokens,
                        temperature=0.1,
                        thinking_config=ThinkingConfig(
                            thinking_budget=thinking_budget,
                            include_thoughts=False  # æ¨è«–éç¨‹ã¯å«ã‚ãªã„
                        )
                    )
                elif HAS_THINKING_CONFIG:
                    config = GenerateContentConfig(
                        max_output_tokens=max_tokens,
                        temperature=0.1,
                    )
                else:
                    # å¤ã„types.GenerateContentConfigã‚’ä½¿ç”¨
                    config = types.GenerateContentConfig(
                        max_output_tokens=max_tokens,
                        temperature=0.1,
                    )
                
                response = client.models.generate_content(
                    model=model,
                    contents=full_message,
                    config=config
                )
                
                # å¿œç­”ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
                result_text = None
                
                try:
                    # ã¾ãšæ¨™æº–çš„ãª.textãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’è©¦ã™
                    if hasattr(response, 'text'):
                        if callable(response.text):
                            # textãŒãƒ¡ã‚½ãƒƒãƒ‰ã®å ´åˆ
                            result_text = response.text()
                        else:
                            # textãŒãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã®å ´åˆ
                            result_text = response.text
                except Exception as e:
                    st.warning(f"response.textã®å–å¾—ã«å¤±æ•—: {e}")
                    
                    # ä»–ã®æ–¹æ³•ã‚’è©¦ã™
                    if hasattr(response, 'candidates') and response.candidates:
                        try:
                            # æœ€åˆã®å€™è£œã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
                            candidate = response.candidates[0]
                            if hasattr(candidate, 'content'):
                                content = candidate.content
                                if hasattr(content, 'parts') and content.parts:
                                    # partsã‹ã‚‰æœ€åˆã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‘ãƒ¼ãƒˆã‚’å–å¾—
                                    for part in content.parts:
                                        if hasattr(part, 'text'):
                                            result_text = part.text
                                            break
                                elif hasattr(content, 'text'):
                                    result_text = content.text
                        except Exception as e2:
                            st.error(f"å€™è£œã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ã«å¤±æ•—: {e2}")
                    
                    # ãã‚Œã§ã‚‚å–å¾—ã§ããªã„å ´åˆã€å¿œç­”ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®è©³ç´°ã‚’è¡¨ç¤º
                    if result_text is None:
                        st.error(f"å¿œç­”ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                        st.error(f"å¿œç­”ã‚¿ã‚¤ãƒ—: {type(response)}")
                        
                        # å¿œç­”ã®å±æ€§ã‚’è©³ã—ãèª¿æŸ»
                        if hasattr(response, '__dict__'):
                            st.error(f"å¿œç­”ã®å†…å®¹: {response.__dict__}")
                        
                        # candidatesã®è©³ç´°ã‚’è¡¨ç¤º
                        if hasattr(response, 'candidates') and response.candidates:
                            st.error(f"å€™è£œã®æ•°: {len(response.candidates)}")
                            if response.candidates:
                                st.error(f"æœ€åˆã®å€™è£œã®å‹: {type(response.candidates[0])}")
                                if hasattr(response.candidates[0], '__dict__'):
                                    st.error(f"æœ€åˆã®å€™è£œã®å†…å®¹: {response.candidates[0].__dict__}")
                
                return result_text
            else:
                st.error("ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return None
        else:
            model_obj = genai.GenerativeModel(model)
            response = model_obj.generate_content(
                full_message,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=max_tokens,
                    temperature=0.1,
                )
            )
            return response.text
            
    except Exception as e:
        st.error(f"Gemini APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
        st.error(f"ãƒ¢ãƒ‡ãƒ«å: {model_name}")
        st.error(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID: {project_id}")
        st.error(f"ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³: {location}")
        import traceback
        st.error(traceback.format_exc())
        return None

# Function to parse JSON from Claude's response
def parse_json_response(response):
    try:
        # å¿œç­”ãŒNoneã¾ãŸã¯ç©ºã®å ´åˆ
        if not response:
            st.error("ç©ºã®å¿œç­”ã‚’å—ä¿¡ã—ã¾ã—ãŸ")
            return None
            
        # ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šæœ€åˆã®100æ–‡å­—ã‚’è¡¨ç¤ºï¼ˆæœ¬ç•ªç’°å¢ƒã§ã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
        # st.info(f"å¿œç­”ã®æœ€åˆã®100æ–‡å­—: {response[:100]}...")
        
        # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»
        if response.strip().startswith("```json"):
            response = response.strip()[7:]  # ```json ã‚’é™¤å»
            if response.endswith("```"):
                response = response[:-3]  # æœ«å°¾ã® ``` ã‚’é™¤å»
        elif response.strip().startswith("```"):
            response = response.strip()[3:]  # ``` ã‚’é™¤å»
            if response.endswith("```"):
                response = response[:-3]  # æœ«å°¾ã® ``` ã‚’é™¤å»
        
        # JSONã®é–‹å§‹ã¨çµ‚äº†ä½ç½®ã‚’æ¢ã™
        start_idx = response.find('{')
        end_idx = response.rfind('}') + 1
        
        # JSONãŒåˆ‡ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯
        if start_idx >= 0:
            # é–‹ãæ‹¬å¼§ã®æ•°ã¨é–‰ã˜æ‹¬å¼§ã®æ•°ã‚’æ•°ãˆã‚‹
            open_brackets = response.count('[')
            close_brackets = response.count(']')
            open_braces = response.count('{')
            close_braces = response.count('}')
            
            # åˆ‡ã‚Œã¦ã„ã‚‹å ´åˆã®å‡¦ç†
            if open_brackets > close_brackets or open_braces > close_braces:
                st.warning("JSONãŒé€”ä¸­ã§åˆ‡ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
                # å¿œç­”ãŒåˆ‡ã‚Œã¦ã„ã‚‹å ´åˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™
                return {
                    "score": 3,  # ä¸­é–“ã‚¹ã‚³ã‚¢
                    "improvements": ["å¿œç­”ãŒé€”ä¸­ã§åˆ‡ã‚ŒãŸãŸã‚ã€å®Œå…¨ãªè©•ä¾¡ãŒã§ãã¾ã›ã‚“ã§ã—ãŸ"]
                }
        
        if start_idx >= 0 and end_idx > start_idx:
            json_str = response[start_idx:end_idx]
            try:
                return json.loads(json_str)
            except json.JSONDecodeError as je:
                st.warning(f"JSONè§£æã‚¨ãƒ©ãƒ¼: {je}")
                # éƒ¨åˆ†çš„ãªJSONã‚’è§£æã—ã¦ã¿ã‚‹
                try:
                    # ä¸å®Œå…¨ãªJSONã‚’ä¿®å¾©ã™ã‚‹è©¦ã¿
                    if '"improvements": [' in json_str and not json_str.rstrip().endswith(']'):
                        json_str = json_str.rstrip() + ']}' if not json_str.rstrip().endswith('}') else json_str
                    return json.loads(json_str)
                except:
                    return {
                        "score": 3,
                        "improvements": ["JSONè§£æã«å¤±æ•—ã—ã¾ã—ãŸ"]
                    }
        else:
            st.warning("Could not find JSON in the response")
            with st.expander("ç”Ÿã®å¿œç­”ã‚’è¡¨ç¤º", expanded=True):
                st.code(response)
            return None
    except Exception as e:
        st.error(f"Error parsing JSON: {e}")
        with st.expander("ç”Ÿã®å¿œç­”ã‚’è¡¨ç¤º", expanded=True):
            st.code(response)
        return None

# Main app
# ã‚«ã‚¹ã‚¿ãƒ CSSã‚’é©ç”¨
st.markdown("""
<style>
    /* ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¤ãƒˆãƒ«ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 20px;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(0,0,0,0.2);
    }
    
    .main-header h1 {
        color: white;
        margin: 0;
        font-size: 3rem;
    }
    
    /* ãƒœã‚¿ãƒ³ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
    .stButton > button {
        transition: all 0.3s ease;
        border-radius: 10px;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(0,0,0,0.3);
    }
    
    /* ãƒ¡ãƒˆãƒªãƒƒã‚¯ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
    [data-testid="metric-container"] {
        background-color: #f8f9fa;
        border: 1px solid #e9ecef;
        padding: 15px;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    
    /* ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
    .stProgress > div > div > div {
        height: 20px;
        border-radius: 10px;
    }
    
    /* ã‚¨ã‚­ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
    .streamlit-expanderHeader {
        font-weight: 600;
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 1rem;
    }
    
    /* ã‚µã‚¯ã‚»ã‚¹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
    .element-container:has(.stSuccess), 
    .element-container:has(.stInfo), 
    .element-container:has(.stWarning), 
    .element-container:has(.stError) {
        animation: fadeIn 0.5s ease;
    }
    
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(-10px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    /* ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
    h2 {
        color: #4a5568;
        border-bottom: 3px solid #667eea;
        padding-bottom: 0.5rem;
        margin-top: 2rem;
    }
    
    h3 {
        color: #4a5568;
        margin-top: 1.5rem;
    }
    
    /* ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
    .stCheckbox {
        padding: 0.5rem;
        border-radius: 8px;
        transition: background-color 0.3s ease;
    }
    
    .stCheckbox:hover {
        background-color: #f8f9fa;
    }
</style>
""", unsafe_allow_html=True)

# ãƒ¡ã‚¤ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼
st.markdown("""
<div class="main-header">
    <h1>ğŸŒ™ mimikoæ ¡æ­£ã‚·ã‚¹ãƒ†ãƒ </h1>
</div>
""", unsafe_allow_html=True)

# Project IDãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã®è­¦å‘Š
if not vertex_ai_project_id:
    st.error("âš ï¸ Vertex AI Project IDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚secrets.tomlãƒ•ã‚¡ã‚¤ãƒ«ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")

# Settings section
with st.expander("âš™ï¸ è©³ç´°è¨­å®š", expanded=False):
    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    selected_model = st.selectbox(
        "ğŸ¯ ãƒ¢ãƒ‡ãƒ«",
        vertex_model_options,
        index=0 if default_model not in vertex_model_options else vertex_model_options.index(default_model),
        key="selected_model"
    )
    
    # Thinking Budgetè¨­å®šï¼ˆ2.5ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã®ã¿ï¼‰
    thinking_budget = 1024  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    if "2.5" in selected_model:
        st.write("### ğŸ§  æ¨è«–è¨­å®š")
        if "2.5-flash" in selected_model:
            thinking_budget = st.slider(
                "Thinking Budget",
                min_value=0,
                max_value=8192,
                value=1024,
                step=128,
                help="æ¨è«–ã«ä½¿ç”¨ã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã€‚0ã«è¨­å®šã™ã‚‹ã¨æ¨è«–æ©Ÿèƒ½ã‚’ç„¡åŠ¹åŒ–ã—ã¾ã™ã€‚"
            )
        elif "2.5-pro" in selected_model:
            thinking_budget = st.slider(
                "Thinking Budget",
                min_value=128,
                max_value=32768,
                value=1024,
                step=128,
                help="æ¨è«–ã«ä½¿ç”¨ã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã€‚Proãƒ¢ãƒ‡ãƒ«ã¯æœ€å°128ãƒˆãƒ¼ã‚¯ãƒ³ãŒå¿…è¦ã§ã™ã€‚"
            )
    
    # æ ¡æ­£ON/OFFè¨­å®š
    st.write("### ğŸ“‹ æ ¡æ­£è¨­å®š")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        enable_tonmana = st.checkbox("ğŸ¨ ãƒˆãƒ³ãƒãƒŠæ ¡æ­£", value=True, key="enable_tonmana")
    
    with col2:
        enable_japanese = st.checkbox("ğŸ“ æ—¥æœ¬èªæ ¡æ­£", value=False, key="enable_japanese")
    
    with col3:
        enable_logic = st.checkbox("ğŸ” ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£", value=True, key="enable_logic")

# Input section
st.header("å…¥åŠ›")

st.info("ç”Ÿæˆã‚¢ãƒ—ãƒªã§å‡ºåŠ›ã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")

uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", type=['csv'])

if uploaded_file is not None:
    # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã‚­ãƒ¼ã¨ã—ã¦ä½¿ç”¨
    file_key = f"file_{uploaded_file.name}_{uploaded_file.size}"
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤‰ã‚ã£ãŸã‹ãƒã‚§ãƒƒã‚¯
    if 'current_file_key' not in st.session_state or st.session_state.current_file_key != file_key:
        st.session_state.current_file_key = file_key
        # æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã€é–¢é€£ã™ã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢
        for key in list(st.session_state.keys()):
            if key.startswith('correction_') or key.startswith('selected_') or key == 'csv_data':
                del st.session_state[key]
    try:
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
        
        # å¿…è¦ãªåˆ—ã®å­˜åœ¨ç¢ºèª
        required_columns = ["id", "è³ªå•", "å›ç­”"]
        if not all(col in df.columns for col in required_columns):
            st.error(f"å¿…é ˆåˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {required_columns}")
        else:
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ—ã®æ¤œå‡ºï¼ˆå‹•çš„ã«å¯¾å¿œï¼‰
            keyword_columns = []
            for col in df.columns:
                # ã‚«ãƒ†ã‚´ãƒªåã§çµ‚ã‚ã‚‹åˆ—ã‚’æ¤œå‡ºï¼ˆä¾‹: ãƒã‚¦ã‚¹1, ã‚µã‚¤ãƒ³2, ãªã©ï¼‰
                if any(col.endswith(str(i)) for i in range(1, 5)):
                    for cat in ["ãƒã‚¦ã‚¹", "ã‚µã‚¤ãƒ³", "å¤©ä½“", "ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆ", "MPè»¸", "ã‚¿ãƒ­ãƒƒãƒˆ"]:
                        if col.startswith(cat):
                            keyword_columns.append(col)
                            break
            
            st.success(f"âœ… {len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            st.write(f"æ¤œå‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ—: {keyword_columns}")
            
            # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
            with st.expander("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", expanded=False):
                st.dataframe(df.head())
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
            st.session_state.csv_data = df
            st.session_state.keyword_columns = keyword_columns
            
    except Exception as e:
        st.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

# CSVå‡¦ç†
if 'csv_data' in st.session_state:
    df = st.session_state.csv_data
    keyword_columns = st.session_state.keyword_columns
    
    # è¡Œé¸æŠ
    st.subheader("ğŸ“ ãƒ‡ãƒ¼ã‚¿é¸æŠ")
    
    # ãƒ‡ãƒ¼ã‚¿ä¸€è¦§ã‚’è¡¨ç¤º
    with st.expander("ãƒ‡ãƒ¼ã‚¿ä¸€è¦§", expanded=False):
        for idx, row in df.iterrows():
            st.write(f"**[{idx+1}]** ID: {row['id']} - {row['è³ªå•'][:80]}...")
    
    # æ•°å€¤å…¥åŠ›ã§é¸æŠ
    col1, col2 = st.columns([1, 3])
    with col1:
        # number_inputã‚’ä½¿ç”¨
        row_number = st.number_input(
            "ãƒ‡ãƒ¼ã‚¿ç•ªå·",
            min_value=1,
            max_value=len(df),
            value=1,
            step=1,
            help=f"1ã‹ã‚‰{len(df)}ã®ç•ªå·ã‚’å…¥åŠ›"
        )
        selected_row_idx = row_number - 1  # 0ãƒ™ãƒ¼ã‚¹ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¤‰æ›
    
    with col2:
        # é¸æŠã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ç°¡æ˜“è¡¨ç¤º
        if 0 <= selected_row_idx < len(df):
            row = df.iloc[selected_row_idx]
            st.write(f"**é¸æŠä¸­:** ID: {row['id']} - {row['è³ªå•'][:50]}...")
    
    # é¸æŠã•ã‚ŒãŸè¡Œã®ãƒ‡ãƒ¼ã‚¿
    selected_row = df.iloc[selected_row_idx]
    
    # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
    with st.expander("é¸æŠã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®è©³ç´°", expanded=True):
        st.write(f"**ID:** {selected_row['id']}")
        st.write(f"**è³ªå•:** {selected_row['è³ªå•']}")
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¡¨ç¤º
        keywords_display = []
        for col in keyword_columns:
            if pd.notna(selected_row[col]):
                category = ''.join([c for c in col if not c.isdigit()])
                keywords_display.append(f"{category}: {selected_row[col]}")
        if keywords_display:
            st.write(f"**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:** {', '.join(keywords_display)}")
        
        st.write(f"**å›ç­”:**")
        st.text_area("", value=selected_row['å›ç­”'], height=150, disabled=True)
    
    # æ ¡æ­£ãƒœã‚¿ãƒ³ã¨ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
    col_btn1, col_btn2 = st.columns([2, 1])
    
    with col_btn1:
        do_correction = st.button("ğŸ” ã“ã®å›ç­”ã‚’æ ¡æ­£ã™ã‚‹", use_container_width=True)
    
    with col_btn2:
        if f'correction_done_{selected_row_idx}' in st.session_state:
            if st.button("ğŸ”„ çµæœã‚’ãƒªã‚»ãƒƒãƒˆ", use_container_width=True):
                # é¸æŠã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã«é–¢é€£ã™ã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢
                keys_to_remove = []
                for key in st.session_state.keys():
                    if f'_{selected_row_idx}' in key:
                        keys_to_remove.append(key)
                
                for key in keys_to_remove:
                    del st.session_state[key]
                
                st.success("æ ¡æ­£çµæœã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
                st.rerun()
    
    # å€‹åˆ¥æ ¡æ­£å®Ÿè¡Œ
    if do_correction or f'correction_done_{selected_row_idx}' in st.session_state:
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
        if f'corrections_{selected_row_idx}' not in st.session_state:
            st.session_state[f'corrections_{selected_row_idx}'] = {}
        
        # è¨­å®šã®æº–å‚™
        current_project_id = vertex_ai_project_id
        current_location = vertex_ai_location
        current_service_account = gcp_service_account
        
        # è³ªå•ã¨å›ç­”ã‚’å–å¾—
        current_question = selected_row['è³ªå•']
        current_answer = selected_row['å›ç­”']
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ•´ç†
        keywords = []
        for col in keyword_columns:
            if pd.notna(selected_row[col]):
                category = ''.join([c for c in col if not c.isdigit()])
                keywords.append(f"{category}: {selected_row[col]}")
        
        # 1. ãƒˆãƒ³ãƒãƒŠæ ¡æ­£
        if f'tonmana_result_{selected_row_idx}' not in st.session_state:
            if st.session_state.get('enable_tonmana', True):
                with st.spinner("ãƒˆãƒ³ãƒãƒŠæ ¡æ­£ä¸­..."):
                    tonmana_message = f"""##QUESTION##
{current_question}

##KEYWORDS##
{', '.join(keywords) if keywords else 'ãªã—'}

##ANSWER_CAND##
{current_answer}
"""
                    tonmana_result = call_gemini(
                        tonmana_prompt, 
                        tonmana_message,
                        selected_model,
                        current_project_id,
                        current_location,
                        current_service_account,
                        thinking_budget=thinking_budget
                    )
                    
                    if tonmana_result:
                        tonmana_json = parse_json_response(tonmana_result)
                        if tonmana_json:
                            st.session_state[f'tonmana_result_{selected_row_idx}'] = tonmana_result
                            st.session_state[f'tonmana_json_{selected_row_idx}'] = tonmana_json
                            
                            st.session_state[f'corrections_{selected_row_idx}']['tonmana'] = {
                                'score': tonmana_json.get('score', 0),
                                'improvements': tonmana_json.get('improvements', [])
                            }
                        else:
                            # JSONãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸå ´åˆã€ç”Ÿã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¡¨ç¤º
                            st.error("ãƒˆãƒ³ãƒãƒŠæ ¡æ­£ã®JSONè§£æã«å¤±æ•—ã—ã¾ã—ãŸ")
                            with st.expander("ãƒ‡ãƒãƒƒã‚°æƒ…å ±", expanded=True):
                                st.code(tonmana_result)
            else:
                # ãƒˆãƒ³ãƒãƒŠæ ¡æ­£ãŒOFFã®å ´åˆ
                st.session_state[f'tonmana_json_{selected_row_idx}'] = {'score': 5, 'improvements': []}
                st.session_state[f'corrections_{selected_row_idx}']['tonmana'] = {
                    'score': 5,
                    'improvements': []
                }
        
        # 2. æ—¥æœ¬èªæ ¡æ­£
        if f'japanese_result_{selected_row_idx}' not in st.session_state:
            if st.session_state.get('enable_japanese', False):
                with st.spinner("æ—¥æœ¬èªæ ¡æ­£ä¸­..."):
                    japanese_result = call_gemini(
                        japanese_prompt,
                        current_answer,
                        selected_model,
                        current_project_id,
                        current_location,
                        current_service_account,
                        thinking_budget=thinking_budget
                    )
                    
                    if japanese_result:
                        japanese_json = parse_json_response(japanese_result)
                        if japanese_json:
                            st.session_state[f'japanese_result_{selected_row_idx}'] = japanese_result
                            st.session_state[f'japanese_json_{selected_row_idx}'] = japanese_json
                            
                            st.session_state[f'corrections_{selected_row_idx}']['japanese'] = {
                                'score': japanese_json.get('score', 0),
                                'improvements': japanese_json.get('improvements', [])
                            }
            else:
                # æ—¥æœ¬èªæ ¡æ­£ãŒOFFã®å ´åˆ
                st.session_state[f'japanese_json_{selected_row_idx}'] = {'score': 5, 'improvements': []}
                st.session_state[f'corrections_{selected_row_idx}']['japanese'] = {
                    'score': 5,
                    'improvements': []
                }
        
        # 3. ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£
        if f'logic_result_{selected_row_idx}' not in st.session_state:
            if st.session_state.get('enable_logic', True):
                with st.spinner("ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£ä¸­..."):
                    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®è©³ç´°æƒ…å ±ã‚’å–å¾—
                    keyword_details = get_keyword_details(keywords)
                    
                    # å…ƒã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã‚¢ãƒ¬ãƒ³ã‚¸ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—
                    original_keywords = []
                    arrange_keywords = []
                    
                    # CSVã®åˆ—ã‹ã‚‰å…ƒã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã‚¢ãƒ¬ãƒ³ã‚¸ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¢ã™
                    for col in df.columns:
                        if 'å…ƒã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰' in col and pd.notna(selected_row[col]):
                            original_keywords.append(selected_row[col])
                        elif 'ã‚¢ãƒ¬ãƒ³ã‚¸ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰' in col and pd.notna(selected_row[col]):
                            arrange_keywords.append(selected_row[col])
                    
                    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è©³ç´°æƒ…å ±ã‚’JSONå½¢å¼ã§æ•´å½¢
                    keyword_info = json.dumps(keyword_details, ensure_ascii=False, indent=2)
                    
                    # ãƒ‡ãƒãƒƒã‚°ç”¨ã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æƒ…å ±ã‚’ä¿å­˜
                    st.session_state[f'keyword_details_{selected_row_idx}'] = keyword_details
                    st.session_state[f'keyword_info_{selected_row_idx}'] = keyword_info
                    st.session_state[f'original_keywords_{selected_row_idx}'] = original_keywords
                    st.session_state[f'arrange_keywords_{selected_row_idx}'] = arrange_keywords
                    
                    logic_message = f"""è³ªå•: {current_question}

ä½¿ç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:
{keyword_info}

å…ƒã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(original_keywords) if original_keywords else 'ãªã—'}

ã‚¢ãƒ¬ãƒ³ã‚¸ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(arrange_keywords) if arrange_keywords else 'ãªã—'}

å›ç­”: {current_answer}
"""
                    logic_result = call_gemini(
                        logic_prompt,
                        logic_message,
                        selected_model,
                        current_project_id,
                        current_location,
                        current_service_account
                    )
                    
                    if logic_result:
                        logic_json = parse_json_response(logic_result)
                        if logic_json:
                            st.session_state[f'logic_result_{selected_row_idx}'] = logic_result
                            st.session_state[f'logic_json_{selected_row_idx}'] = logic_json
                            
                            st.session_state[f'corrections_{selected_row_idx}']['logic'] = {
                                'score': logic_json.get('score', 0),
                                'improvements': logic_json.get('improvements', [])
                            }
            else:
                # ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£ãŒOFFã®å ´åˆ
                st.session_state[f'logic_json_{selected_row_idx}'] = {'score': 5, 'improvements': []}
                st.session_state[f'corrections_{selected_row_idx}']['logic'] = {
                    'score': 5,
                    'improvements': []
                }
        
        # æ ¡æ­£å®Œäº†ãƒ•ãƒ©ã‚°
        st.session_state[f'correction_done_{selected_row_idx}'] = True
        
        # çµæœè¡¨ç¤º
        st.header("ğŸ“Š æ ¡æ­£çµæœ")
        
        # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
        total_score = 0
        if f'corrections_{selected_row_idx}' in st.session_state:
            corrections = st.session_state[f'corrections_{selected_row_idx}']
            for correction_type in ['tonmana', 'japanese', 'logic']:
                if correction_type in corrections:
                    total_score += corrections[correction_type].get('score', 0)
        
        # ã‚¹ã‚³ã‚¢ã«å¿œã˜ã¦è‰²åˆ†ã‘ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        score_percentage = (total_score / 15) * 100
        
        # ã‚¹ã‚³ã‚¢ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚«ãƒ¼ãƒ‰å½¢å¼ã§è¡¨ç¤º
        if score_percentage >= 80:
            st.markdown(f"""
            <div style='background: linear-gradient(135deg, #4caf50 0%, #8bc34a 100%); 
                        padding: 20px; border-radius: 15px; text-align: center; color: white;
                        box-shadow: 0 4px 15px rgba(76, 175, 80, 0.3);'>
                <h2 style='margin: 0; color: white;'>ğŸ‰ ç·åˆã‚¹ã‚³ã‚¢: {total_score}/15ç‚¹</h2>
            </div>
            """, unsafe_allow_html=True)
        elif score_percentage >= 60:
            st.markdown(f"""
            <div style='background: linear-gradient(135deg, #2196f3 0%, #64b5f6 100%); 
                        padding: 20px; border-radius: 15px; text-align: center; color: white;
                        box-shadow: 0 4px 15px rgba(33, 150, 243, 0.3);'>
                <h2 style='margin: 0; color: white;'>ğŸ“Š ç·åˆã‚¹ã‚³ã‚¢: {total_score}/15ç‚¹</h2>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown(f"""
            <div style='background: linear-gradient(135deg, #ff9800 0%, #ffb74d 100%); 
                        padding: 20px; border-radius: 15px; text-align: center; color: white;
                        box-shadow: 0 4px 15px rgba(255, 152, 0, 0.3);'>
                <h2 style='margin: 0; color: white;'>âš ï¸ ç·åˆã‚¹ã‚³ã‚¢: {total_score}/15ç‚¹</h2>
            </div>
            """, unsafe_allow_html=True)
        
        st.markdown("<br>", unsafe_allow_html=True)
        
        # æ”¹å–„ç‚¹é¸æŠç”¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ–
        if f'selected_tonmana_{selected_row_idx}' not in st.session_state:
            st.session_state[f'selected_tonmana_{selected_row_idx}'] = []
        if f'selected_japanese_{selected_row_idx}' not in st.session_state:
            st.session_state[f'selected_japanese_{selected_row_idx}'] = []
        if f'selected_logic_{selected_row_idx}' not in st.session_state:
            st.session_state[f'selected_logic_{selected_row_idx}'] = []
        
        # 1. ãƒˆãƒ³ãƒãƒŠæ ¡æ­£çµæœ
        if f'tonmana_json_{selected_row_idx}' in st.session_state:
            with st.container():
                st.subheader("ğŸ¨ ãƒˆãƒ³ãƒãƒŠæ ¡æ­£çµæœ")
                tonmana_json = st.session_state[f'tonmana_json_{selected_row_idx}']
                
                # ã‚¹ã‚³ã‚¢ã‚’ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã§è¡¨ç¤º
                col1, col2, col3 = st.columns([2, 1, 3])
                with col1:
                    score = tonmana_json.get('score', 0)
                    st.progress(score / 5, text=f"ã‚¹ã‚³ã‚¢: {score}/5")
                
                with col2:
                    # ã‚¹ã‚³ã‚¢ã«å¿œã˜ãŸçµµæ–‡å­—
                    if score >= 4:
                        st.markdown("### âœ…")
                    elif score >= 3:
                        st.markdown("### âš ï¸")
                    else:
                        st.markdown("### âŒ")
                
                # æ ¡æ­£ãŒOFFã®å ´åˆã®è¡¨ç¤º
                if not st.session_state.get('enable_tonmana', True):
                    with col3:
                        st.info("ãƒˆãƒ³ãƒãƒŠæ ¡æ­£ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸ")
            
            improvements = tonmana_json.get('improvements', [])
            if improvements:
                with st.expander(f"ğŸ’¡ æ”¹å–„ç‚¹ ({len(improvements)}ä»¶)", expanded=True):
                    st.caption("æ”¹å–„ã‚’é©ç”¨ã—ãŸã„é …ç›®ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š")
                    for i, improvement in enumerate(improvements):
                        # æ”¹å–„ç‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å®‰å…¨ã«å‡¦ç†
                        safe_improvement = str(improvement).replace('\n', ' ').replace('\r', ' ').strip()
                        # é•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚ã‚‹
                        display_text = safe_improvement[:200] + "..." if len(safe_improvement) > 200 else safe_improvement
                        
                        is_selected = improvement in st.session_state[f'selected_tonmana_{selected_row_idx}']
                        
                        # é¸æŠçŠ¶æ…‹ã«å¿œã˜ã¦èƒŒæ™¯è‰²ã‚’å¤‰æ›´
                        if is_selected:
                            st.markdown(f"<div style='background-color: #e3f2fd; padding: 10px; border-radius: 5px; margin: 5px 0;'>", unsafe_allow_html=True)
                        else:
                            st.markdown(f"<div style='background-color: #f5f5f5; padding: 10px; border-radius: 5px; margin: 5px 0;'>", unsafe_allow_html=True)
                        
                        if st.checkbox(f"æ”¹å–„ç‚¹ {i+1}", key=f"tonmana_cb_{selected_row_idx}_{i}", value=is_selected, help=safe_improvement):
                            if improvement not in st.session_state[f'selected_tonmana_{selected_row_idx}']:
                                st.session_state[f'selected_tonmana_{selected_row_idx}'].append(improvement)
                        else:
                            if improvement in st.session_state[f'selected_tonmana_{selected_row_idx}']:
                                st.session_state[f'selected_tonmana_{selected_row_idx}'].remove(improvement)
                        
                        st.caption(display_text)
                        st.markdown("</div>", unsafe_allow_html=True)
            else:
                st.success("âœ… æ”¹å–„ç‚¹ã¯ã‚ã‚Šã¾ã›ã‚“")
        
        # 2. æ—¥æœ¬èªæ ¡æ­£çµæœ
        if f'japanese_json_{selected_row_idx}' in st.session_state:
            with st.container():
                st.subheader("ğŸ“ æ—¥æœ¬èªæ ¡æ­£çµæœ")
                japanese_json = st.session_state[f'japanese_json_{selected_row_idx}']
                
                # ã‚¹ã‚³ã‚¢ã‚’ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã§è¡¨ç¤º
                col1, col2, col3 = st.columns([2, 1, 3])
                with col1:
                    score = japanese_json.get('score', 0)
                    st.progress(score / 5, text=f"ã‚¹ã‚³ã‚¢: {score}/5")
                
                with col2:
                    # ã‚¹ã‚³ã‚¢ã«å¿œã˜ãŸçµµæ–‡å­—
                    if score >= 4:
                        st.markdown("### âœ…")
                    elif score >= 3:
                        st.markdown("### âš ï¸")
                    else:
                        st.markdown("### âŒ")
                
                # æ ¡æ­£ãŒOFFã®å ´åˆã®è¡¨ç¤º
                if not st.session_state.get('enable_japanese', False):
                    with col3:
                        st.info("æ—¥æœ¬èªæ ¡æ­£ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸ")
                
                improvements = japanese_json.get('improvements', [])
                if improvements:
                    with st.expander(f"ğŸ’¡ æ”¹å–„ç‚¹ ({len(improvements)}ä»¶)", expanded=True):
                        st.caption("æ”¹å–„ã‚’é©ç”¨ã—ãŸã„é …ç›®ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š")
                        for i, improvement in enumerate(improvements):
                            # æ”¹å–„ç‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å®‰å…¨ã«å‡¦ç†
                            safe_improvement = str(improvement).replace('\n', ' ').replace('\r', ' ').strip()
                            # é•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚ã‚‹
                            display_text = safe_improvement[:200] + "..." if len(safe_improvement) > 200 else safe_improvement
                            
                            is_selected = improvement in st.session_state[f'selected_japanese_{selected_row_idx}']
                            
                            # é¸æŠçŠ¶æ…‹ã«å¿œã˜ã¦èƒŒæ™¯è‰²ã‚’å¤‰æ›´
                            if is_selected:
                                st.markdown(f"<div style='background-color: #fff3e0; padding: 10px; border-radius: 5px; margin: 5px 0;'>", unsafe_allow_html=True)
                            else:
                                st.markdown(f"<div style='background-color: #f5f5f5; padding: 10px; border-radius: 5px; margin: 5px 0;'>", unsafe_allow_html=True)
                            
                            if st.checkbox(f"æ”¹å–„ç‚¹ {i+1}", key=f"japanese_cb_{selected_row_idx}_{i}", value=is_selected, help=safe_improvement):
                                if improvement not in st.session_state[f'selected_japanese_{selected_row_idx}']:
                                    st.session_state[f'selected_japanese_{selected_row_idx}'].append(improvement)
                            else:
                                if improvement in st.session_state[f'selected_japanese_{selected_row_idx}']:
                                    st.session_state[f'selected_japanese_{selected_row_idx}'].remove(improvement)
                            
                            st.caption(display_text)
                            st.markdown("</div>", unsafe_allow_html=True)
                else:
                    st.success("âœ… æ”¹å–„ç‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ - æ—¥æœ¬èªã¨ã—ã¦å®Œç’§ã§ã™ï¼")
        
        # 3. ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£çµæœ
        if f'logic_json_{selected_row_idx}' in st.session_state:
            with st.container():
                st.subheader("ğŸ” ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£çµæœ")
                logic_json = st.session_state[f'logic_json_{selected_row_idx}']
                
                # ã‚¹ã‚³ã‚¢ã‚’ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã§è¡¨ç¤º
                col1, col2, col3 = st.columns([2, 1, 3])
                with col1:
                    score = logic_json.get('score', 0)
                    st.progress(score / 5, text=f"ã‚¹ã‚³ã‚¢: {score}/5")
                
                with col2:
                    # ã‚¹ã‚³ã‚¢ã«å¿œã˜ãŸçµµæ–‡å­—
                    if score >= 4:
                        st.markdown("### âœ…")
                    elif score >= 3:
                        st.markdown("### âš ï¸")
                    else:
                        st.markdown("### âŒ")
                
                # æ ¡æ­£ãŒOFFã®å ´åˆã®è¡¨ç¤º
                if not st.session_state.get('enable_logic', True):
                    with col3:
                        st.info("ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸ")
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è©³ç´°ã‚’è¡¨ç¤º
            with st.expander("ğŸ”§ ãƒ‡ãƒãƒƒã‚°: AIã«é€ä¿¡ã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æƒ…å ±", expanded=False):
                # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
                st.write("**ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆCSVã‹ã‚‰å–å¾—ï¼‰:**")
                st.write(f"{', '.join(keywords) if keywords else 'ãªã—'}")
                
                # å…ƒã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã‚¢ãƒ¬ãƒ³ã‚¸ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                if f'original_keywords_{selected_row_idx}' in st.session_state:
                    st.write("\n**å…ƒã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:**")
                    orig_kws = st.session_state[f'original_keywords_{selected_row_idx}']
                    st.write(f"{', '.join(orig_kws) if orig_kws else 'ãªã—'}")
                
                if f'arrange_keywords_{selected_row_idx}' in st.session_state:
                    st.write("\n**ã‚¢ãƒ¬ãƒ³ã‚¸ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:**")
                    arr_kws = st.session_state[f'arrange_keywords_{selected_row_idx}']
                    st.write(f"{', '.join(arr_kws) if arr_kws else 'ãªã—'}")
                
                if f'keyword_details_{selected_row_idx}' in st.session_state:
                    keyword_details = st.session_state[f'keyword_details_{selected_row_idx}']
                    st.write("\n**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è©³ç´°æƒ…å ±ï¼ˆå„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å†…å®¹ï¼‰:**")
                    
                    for i, detail in enumerate(keyword_details, 1):
                        st.write(f"\n**[{i}] {detail.get('ã‚«ãƒ†ã‚´ãƒª', '')}: {detail.get('ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰', '')}**")
                        
                        # è©³ç´°æƒ…å ±ã‚’è¡¨å½¢å¼ã§è¡¨ç¤º
                        detail_items = []
                        for key, value in detail.items():
                            if key not in ['ã‚«ãƒ†ã‚´ãƒª', 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰']:
                                detail_items.append(f"- **{key}**: {value}")
                        
                        if detail_items:
                            for item in detail_items:
                                st.write(item)
                        else:
                            st.write("- è©³ç´°æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                    
                    st.write("\n**JSONå½¢å¼ï¼ˆAIã«é€ä¿¡ã•ã‚ŒãŸå†…å®¹ï¼‰:**")
                    st.code(st.session_state[f'keyword_info_{selected_row_idx}'], language='json')
            
            improvements = logic_json.get('improvements', [])
            if improvements:
                with st.expander(f"ğŸ’¡ æ”¹å–„ç‚¹ ({len(improvements)}ä»¶)", expanded=True):
                    st.caption("æ”¹å–„ã‚’é©ç”¨ã—ãŸã„é …ç›®ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š")
                    for i, improvement in enumerate(improvements):
                        # æ”¹å–„ç‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å®‰å…¨ã«å‡¦ç†
                        safe_improvement = str(improvement).replace('\n', ' ').replace('\r', ' ').strip()
                        # é•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚ã‚‹
                        display_text = safe_improvement[:200] + "..." if len(safe_improvement) > 200 else safe_improvement
                        
                        is_selected = improvement in st.session_state[f'selected_logic_{selected_row_idx}']
                        
                        # é¸æŠçŠ¶æ…‹ã«å¿œã˜ã¦èƒŒæ™¯è‰²ã‚’å¤‰æ›´
                        if is_selected:
                            st.markdown(f"<div style='background-color: #ffebee; padding: 10px; border-radius: 5px; margin: 5px 0;'>", unsafe_allow_html=True)
                        else:
                            st.markdown(f"<div style='background-color: #f5f5f5; padding: 10px; border-radius: 5px; margin: 5px 0;'>", unsafe_allow_html=True)
                        
                        if st.checkbox(f"æ”¹å–„ç‚¹ {i+1}", key=f"logic_cb_{selected_row_idx}_{i}", value=is_selected, help=safe_improvement):
                            if improvement not in st.session_state[f'selected_logic_{selected_row_idx}']:
                                st.session_state[f'selected_logic_{selected_row_idx}'].append(improvement)
                        else:
                            if improvement in st.session_state[f'selected_logic_{selected_row_idx}']:
                                st.session_state[f'selected_logic_{selected_row_idx}'].remove(improvement)
                        
                        st.caption(display_text)
                        st.markdown("</div>", unsafe_allow_html=True)
            else:
                st.success("âœ… æ”¹å–„ç‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ - ãƒ­ã‚¸ãƒƒã‚¯ã¯å®Œç’§ã§ã™ï¼")
        
        # ç·åˆæ ¡æ­£ãƒœã‚¿ãƒ³
        st.header("âœ¨ ç·åˆæ ¡æ­£")
        if st.button("é¸æŠã—ãŸæ”¹å–„ç‚¹ã§ç·åˆæ ¡æ­£ã‚’å®Ÿè¡Œ") or f'comprehensive_result_{selected_row_idx}' in st.session_state:
            if f'comprehensive_result_{selected_row_idx}' not in st.session_state:
                with st.spinner("ç·åˆæ ¡æ­£ä¸­..."):
                    # é¸æŠã•ã‚ŒãŸæ”¹å–„ç‚¹ã‚’æ•´ç†
                    selected_improvements = {
                        "ãƒˆãƒ³ãƒãƒŠæ ¡æ­£": st.session_state.get(f'selected_tonmana_{selected_row_idx}', []),
                        "æ—¥æœ¬èªæ ¡æ­£": st.session_state.get(f'selected_japanese_{selected_row_idx}', []),
                        "ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£": st.session_state.get(f'selected_logic_{selected_row_idx}', [])
                    }
                    
                    # ã‚¹ã‚³ã‚¢ã‚’æ•´ç†
                    scores = {}
                    if f'corrections_{selected_row_idx}' in st.session_state:
                        corrections = st.session_state[f'corrections_{selected_row_idx}']
                        if 'tonmana' in corrections:
                            scores["ãƒˆãƒ³ãƒãƒŠæ ¡æ­£"] = corrections['tonmana'].get('score', 0)
                        if 'japanese' in corrections:
                            scores["æ—¥æœ¬èªæ ¡æ­£"] = corrections['japanese'].get('score', 0)
                        if 'logic' in corrections:
                            scores["ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£"] = corrections['logic'].get('score', 0)
                    
                    # ç·åˆæ ¡æ­£ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆ
                    comprehensive_message = f"""AIå ã„å¸«ã®å›ç­”:
{current_answer}

ä½¿ç”¨ã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:
{', '.join(keywords) if keywords else 'ãªã—'}

å„æ ¡æ­£AIã®æ¡ç‚¹çµæœ:
"""
                    for correction_type, score in scores.items():
                        comprehensive_message += f"{correction_type}: {score}/5\n"
                    
                    comprehensive_message += "\né¸æŠã•ã‚ŒãŸæ”¹å–„ç‚¹:\n"
                    for correction_type, improvements in selected_improvements.items():
                        if improvements:
                            comprehensive_message += f"\n{correction_type}:\n"
                            for i, improvement in enumerate(improvements):
                                comprehensive_message += f"{i+1}. {improvement}\n"
                    
                    # ç·åˆæ ¡æ­£å®Ÿè¡Œï¼ˆé•·ã„å‡ºåŠ›ã®ãŸã‚ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å¢—ã‚„ã™ï¼‰
                    comprehensive_result = call_gemini(
                        comprehensive_prompt,
                        comprehensive_message,
                        selected_model,
                        current_project_id,
                        current_location,
                        current_service_account,
                        max_tokens=4000,  # ç·åˆæ ¡æ­£ã¯é•·ã„æ–‡ç« ã‚’å‡ºåŠ›ã™ã‚‹ãŸã‚å¤§ããè¨­å®š
                        thinking_budget=thinking_budget
                    )
                    
                    if comprehensive_result:
                        st.session_state[f'comprehensive_result_{selected_row_idx}'] = comprehensive_result
            
            # ç·åˆæ ¡æ­£çµæœè¡¨ç¤º
            if f'comprehensive_result_{selected_row_idx}' in st.session_state:
                st.subheader("ğŸ“ ç·åˆæ ¡æ­£çµæœ")
                
                # å…ƒã®å›ç­”ã¨æ¯”è¼ƒè¡¨ç¤º
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**ğŸ”¸ å…ƒã®å›ç­”**")
                    with st.container():
                        st.markdown(f"<div style='background-color: #fff3e0; padding: 15px; border-radius: 10px; max-height: 400px; overflow-y: auto;'>{current_answer}</div>", unsafe_allow_html=True)
                
                with col2:
                    st.markdown("**âœ¨ æ ¡æ­£å¾Œã®å›ç­”**")
                    with st.container():
                        corrected_text = st.session_state[f'comprehensive_result_{selected_row_idx}']
                        st.markdown(f"<div style='background-color: #e8f5e9; padding: 15px; border-radius: 10px; max-height: 400px; overflow-y: auto;'>{corrected_text}</div>", unsafe_allow_html=True)
                
                # é©ç”¨ã•ã‚ŒãŸæ”¹å–„ç‚¹ã®ã‚µãƒãƒªãƒ¼
                if any([
                    st.session_state.get(f'selected_tonmana_{selected_row_idx}', []),
                    st.session_state.get(f'selected_japanese_{selected_row_idx}', []),
                    st.session_state.get(f'selected_logic_{selected_row_idx}', [])
                ]):
                    with st.expander("ğŸ“Œ é©ç”¨ã•ã‚ŒãŸæ”¹å–„ç‚¹", expanded=False):
                        if st.session_state.get(f'selected_tonmana_{selected_row_idx}'):
                            st.markdown("**ğŸ¨ ãƒˆãƒ³ãƒãƒŠæ”¹å–„:**")
                            for imp in st.session_state[f'selected_tonmana_{selected_row_idx}']:
                                st.write(f"- {imp}")
                        
                        if st.session_state.get(f'selected_japanese_{selected_row_idx}'):
                            st.markdown("**ğŸ“ æ—¥æœ¬èªæ”¹å–„:**")
                            for imp in st.session_state[f'selected_japanese_{selected_row_idx}']:
                                st.write(f"- {imp}")
                        
                        if st.session_state.get(f'selected_logic_{selected_row_idx}'):
                            st.markdown("**ğŸ” ãƒ­ã‚¸ãƒƒã‚¯æ”¹å–„:**")
                            for imp in st.session_state[f'selected_logic_{selected_row_idx}']:
                                st.write(f"- {imp}")
    
    # åŒºåˆ‡ã‚Šç·š
    st.divider()
    
    # å€‹åˆ¥æ ¡æ­£çµæœã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    st.header("ğŸ“¥ å€‹åˆ¥æ ¡æ­£çµæœã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    
    # æ ¡æ­£æ¸ˆã¿ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
    corrected_data = []
    for idx in range(len(df)):
        if f'correction_done_{idx}' in st.session_state:
            row_data = df.iloc[idx].to_dict()
            
            # æ ¡æ­£çµæœã‚’è¿½åŠ 
            if f'corrections_{idx}' in st.session_state:
                corrections = st.session_state[f'corrections_{idx}']
                
                # ã‚¹ã‚³ã‚¢ã‚’è¿½åŠ 
                row_data['ãƒˆãƒ³ãƒãƒŠã‚¹ã‚³ã‚¢'] = corrections.get('tonmana', {}).get('score', 0)
                row_data['æ—¥æœ¬èªã‚¹ã‚³ã‚¢'] = corrections.get('japanese', {}).get('score', 0)
                row_data['ãƒ­ã‚¸ãƒƒã‚¯ã‚¹ã‚³ã‚¢'] = corrections.get('logic', {}).get('score', 0)
                row_data['ç·åˆã‚¹ã‚³ã‚¢'] = (
                    row_data['ãƒˆãƒ³ãƒãƒŠã‚¹ã‚³ã‚¢'] + 
                    row_data['æ—¥æœ¬èªã‚¹ã‚³ã‚¢'] + 
                    row_data['ãƒ­ã‚¸ãƒƒã‚¯ã‚¹ã‚³ã‚¢']
                )
                
                # æ”¹å–„ç‚¹ã‚’è¿½åŠ 
                improvements = []
                if corrections.get('tonmana', {}).get('improvements'):
                    improvements.extend([f"ã€ãƒˆãƒ³ãƒãƒŠã€‘{imp}" for imp in corrections['tonmana']['improvements']])
                if corrections.get('japanese', {}).get('improvements'):
                    improvements.extend([f"ã€æ—¥æœ¬èªã€‘{imp}" for imp in corrections['japanese']['improvements']])
                if corrections.get('logic', {}).get('improvements'):
                    improvements.extend([f"ã€ãƒ­ã‚¸ãƒƒã‚¯ã€‘{imp}" for imp in corrections['logic']['improvements']])
                
                row_data['æ”¹å–„ç‚¹'] = '\n'.join(improvements) if improvements else ''
                
                # ç·åˆæ ¡æ­£çµæœã‚’è¿½åŠ 
                if f'comprehensive_result_{idx}' in st.session_state:
                    row_data['ç·åˆæ ¡æ­£çµæœ'] = st.session_state[f'comprehensive_result_{idx}']
                else:
                    row_data['ç·åˆæ ¡æ­£çµæœ'] = ''
                
            corrected_data.append(row_data)
    
    if corrected_data:
        # ã‚¹ã‚³ã‚¢ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        col_sum1, col_sum2, col_sum3 = st.columns(3)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
        result_df = pd.DataFrame(corrected_data)
        
        # å¹³å‡ã‚¹ã‚³ã‚¢è¨ˆç®—
        avg_tonmana = result_df['ãƒˆãƒ³ãƒãƒŠã‚¹ã‚³ã‚¢'].mean() if 'ãƒˆãƒ³ãƒãƒŠã‚¹ã‚³ã‚¢' in result_df else 0
        avg_japanese = result_df['æ—¥æœ¬èªã‚¹ã‚³ã‚¢'].mean() if 'æ—¥æœ¬èªã‚¹ã‚³ã‚¢' in result_df else 0
        avg_logic = result_df['ãƒ­ã‚¸ãƒƒã‚¯ã‚¹ã‚³ã‚¢'].mean() if 'ãƒ­ã‚¸ãƒƒã‚¯ã‚¹ã‚³ã‚¢' in result_df else 0
        
        with col_sum1:
            st.metric("ğŸ¨ ãƒˆãƒ³ãƒãƒŠå¹³å‡", f"{avg_tonmana:.2f}/5")
        with col_sum2:
            st.metric("ğŸ“ æ—¥æœ¬èªå¹³å‡", f"{avg_japanese:.2f}/5")
        with col_sum3:
            st.metric("ğŸ” ãƒ­ã‚¸ãƒƒã‚¯å¹³å‡", f"{avg_logic:.2f}/5")
        
        st.success(f"âœ… {len(corrected_data)}ä»¶ã®æ ¡æ­£æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã™")
        
        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
        with st.expander("ğŸ“Š æ ¡æ­£æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", expanded=False):
            display_columns = ['id', 'è³ªå•', 'ãƒˆãƒ³ãƒãƒŠã‚¹ã‚³ã‚¢', 'æ—¥æœ¬èªã‚¹ã‚³ã‚¢', 'ãƒ­ã‚¸ãƒƒã‚¯ã‚¹ã‚³ã‚¢', 'ç·åˆã‚¹ã‚³ã‚¢']
            # ã‚¹ã‚³ã‚¢ã«å¿œã˜ã¦è‰²ä»˜ã‘
            styled_df = result_df[display_columns].style.applymap(
                lambda x: 'background-color: #e8f5e9' if isinstance(x, (int, float)) and x >= 4 else 
                         'background-color: #fff3e0' if isinstance(x, (int, float)) and x >= 2 else 
                         'background-color: #ffebee' if isinstance(x, (int, float)) and x < 2 else '',
                subset=['ãƒˆãƒ³ãƒãƒŠã‚¹ã‚³ã‚¢', 'æ—¥æœ¬èªã‚¹ã‚³ã‚¢', 'ãƒ­ã‚¸ãƒƒã‚¯ã‚¹ã‚³ã‚¢', 'ç·åˆã‚¹ã‚³ã‚¢']
            )
            st.dataframe(styled_df)
        
        # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
        output_buffer = io.StringIO()
        result_df.to_csv(output_buffer, index=False, encoding='utf-8-sig')
        
        col_dl1, col_dl2, col_dl3 = st.columns([1, 2, 1])
        with col_dl2:
            st.download_button(
                label="ğŸ“¥ å€‹åˆ¥æ ¡æ­£çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=output_buffer.getvalue(),
                file_name=f"mimiko_individual_corrections_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                use_container_width=True,
                type="primary"
            )
    else:
        st.info("ã¾ã æ ¡æ­£æ¸ˆã¿ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä¸Šè¨˜ã§å€‹åˆ¥ã«æ ¡æ­£ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    
    # åŒºåˆ‡ã‚Šç·š
    st.divider()
    
    # ä¸€æ‹¬å‡¦ç†ãƒœã‚¿ãƒ³
    with st.container():
        st.header("ğŸš€ ä¸€æ‹¬å‡¦ç†")
        
        if len(df) > 20:
            st.warning(f"âš ï¸ å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆ{len(df)}ä»¶ï¼‰ã®ä¸€æ‹¬å‡¦ç†ã«ã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™")
        
        col_batch1, col_batch2, col_batch3 = st.columns([1, 2, 1])
        with col_batch2:
            if st.button("ğŸ¯ å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬æ ¡æ­£", type="secondary", use_container_width=True):
                # çµæœã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®åˆ—ã‚’è¿½åŠ 
                df['ãƒˆãƒ³ãƒãƒŠã‚¹ã‚³ã‚¢'] = 0
                df['æ—¥æœ¬èªã‚¹ã‚³ã‚¢'] = 0
                df['ãƒ­ã‚¸ãƒƒã‚¯ã‚¹ã‚³ã‚¢'] = 0
                df['ç·åˆã‚¹ã‚³ã‚¢'] = 0
                df['æ”¹å–„ç‚¹'] = ""
                df['ç·åˆæ ¡æ­£çµæœ'] = ""
                
                # è¨­å®šã®æº–å‚™
                current_project_id = vertex_ai_project_id
                current_location = vertex_ai_location
                current_service_account = gcp_service_account
                
                # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # å„è¡Œã‚’å‡¦ç†
                for index, row in df.iterrows():
                    status_text.text(f"å‡¦ç†ä¸­: {index + 1}/{len(df)}")
                    
                    # è³ªå•ã¨å›ç­”ã‚’å–å¾—
                    current_question = row['è³ªå•']
                    current_answer = row['å›ç­”']
            
                    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ•´ç†
                    keywords = []
                    for col in keyword_columns:
                        if pd.notna(row[col]):
                            # ã‚«ãƒ†ã‚´ãƒªåã‚’æŠ½å‡ºï¼ˆä¾‹: "ãƒã‚¦ã‚¹1" -> "ãƒã‚¦ã‚¹"ï¼‰
                            category = ''.join([c for c in col if not c.isdigit()])
                            keywords.append(f"{category}: {row[col]}")
            
                    # 1. ãƒˆãƒ³ãƒãƒŠæ ¡æ­£
                    if st.session_state.get('enable_tonmana', True):
                        tonmana_message = f"""##QUESTION##
{current_question}

##KEYWORDS##
{', '.join(keywords) if keywords else 'ãªã—'}

##ANSWER_CAND##
{current_answer}
"""
                        tonmana_result = call_gemini(
                            tonmana_prompt, 
                            tonmana_message,
                            selected_model,
                            current_project_id,
                            current_location,
                            current_service_account,
                            thinking_budget=thinking_budget
                        )
                        
                        tonmana_json = parse_json_response(tonmana_result) if tonmana_result else None
                        if tonmana_json:
                            df.at[index, 'ãƒˆãƒ³ãƒãƒŠã‚¹ã‚³ã‚¢'] = tonmana_json.get('score', 0)
                            improvements = tonmana_json.get('improvements', [])
                            if improvements:
                                df.at[index, 'æ”¹å–„ç‚¹'] += f"ã€ãƒˆãƒ³ãƒãƒŠã€‘{', '.join(improvements)}\n"
                    else:
                        df.at[index, 'ãƒˆãƒ³ãƒãƒŠã‚¹ã‚³ã‚¢'] = 5
            
                    # 2. æ—¥æœ¬èªæ ¡æ­£
                    if st.session_state.get('enable_japanese', False):
                        japanese_result = call_gemini(
                            japanese_prompt,
                            current_answer,
                            selected_model,
                            current_project_id,
                            current_location,
                            current_service_account,
                            thinking_budget=thinking_budget
                        )
                        
                        japanese_json = parse_json_response(japanese_result) if japanese_result else None
                        if japanese_json:
                            df.at[index, 'æ—¥æœ¬èªã‚¹ã‚³ã‚¢'] = japanese_json.get('score', 0)
                            improvements = japanese_json.get('improvements', [])
                            if improvements:
                                df.at[index, 'æ”¹å–„ç‚¹'] += f"ã€æ—¥æœ¬èªã€‘{', '.join(improvements)}\n"
                    else:
                        df.at[index, 'æ—¥æœ¬èªã‚¹ã‚³ã‚¢'] = 5
            
                    # 3. ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£
                    if st.session_state.get('enable_logic', True):
                        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®è©³ç´°æƒ…å ±ã‚’å–å¾—
                        keyword_details = get_keyword_details(keywords)
                        
                        # å…ƒã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã‚¢ãƒ¬ãƒ³ã‚¸ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—
                        original_keywords = []
                        arrange_keywords = []
                        
                        # CSVã®åˆ—ã‹ã‚‰å…ƒã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã‚¢ãƒ¬ãƒ³ã‚¸ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¢ã™
                        for col in df.columns:
                            if 'å…ƒã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰' in col and pd.notna(row[col]):
                                original_keywords.append(row[col])
                            elif 'ã‚¢ãƒ¬ãƒ³ã‚¸ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰' in col and pd.notna(row[col]):
                                arrange_keywords.append(row[col])
                        
                        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è©³ç´°æƒ…å ±ã‚’JSONå½¢å¼ã§æ•´å½¢
                        keyword_info = json.dumps(keyword_details, ensure_ascii=False, indent=2)
                        
                        logic_message = f"""è³ªå•: {current_question}

ä½¿ç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:
{keyword_info}

å…ƒã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(original_keywords) if original_keywords else 'ãªã—'}

ã‚¢ãƒ¬ãƒ³ã‚¸ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(arrange_keywords) if arrange_keywords else 'ãªã—'}

å›ç­”: {current_answer}
"""
                        logic_result = call_gemini(
                            logic_prompt,
                            logic_message,
                            selected_model,
                            current_project_id,
                            current_location,
                            current_service_account,
                            thinking_budget=thinking_budget
                        )
                        
                        logic_json = parse_json_response(logic_result) if logic_result else None
                        if logic_json:
                            df.at[index, 'ãƒ­ã‚¸ãƒƒã‚¯ã‚¹ã‚³ã‚¢'] = logic_json.get('score', 0)
                            improvements = logic_json.get('improvements', [])
                            if improvements:
                                df.at[index, 'æ”¹å–„ç‚¹'] += f"ã€ãƒ­ã‚¸ãƒƒã‚¯ã€‘{', '.join(improvements)}\n"
                    else:
                        df.at[index, 'ãƒ­ã‚¸ãƒƒã‚¯ã‚¹ã‚³ã‚¢'] = 5
            
                    # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
                    total_score = df.at[index, 'ãƒˆãƒ³ãƒãƒŠã‚¹ã‚³ã‚¢'] + df.at[index, 'æ—¥æœ¬èªã‚¹ã‚³ã‚¢'] + df.at[index, 'ãƒ­ã‚¸ãƒƒã‚¯ã‚¹ã‚³ã‚¢']
                    df.at[index, 'ç·åˆã‚¹ã‚³ã‚¢'] = total_score
                    
                    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°
                    progress_bar.progress((index + 1) / len(df))
                
                status_text.text("å‡¦ç†å®Œäº†!")
                
                # çµæœè¡¨ç¤º
                st.subheader("æ ¡æ­£çµæœã‚µãƒãƒªãƒ¼")
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    avg_tonmana = df['ãƒˆãƒ³ãƒãƒŠã‚¹ã‚³ã‚¢'].mean()
                    st.metric("å¹³å‡ãƒˆãƒ³ãƒãƒŠã‚¹ã‚³ã‚¢", f"{avg_tonmana:.2f}/5")
                
                with col2:
                    avg_japanese = df['æ—¥æœ¬èªã‚¹ã‚³ã‚¢'].mean()
                    st.metric("å¹³å‡æ—¥æœ¬èªã‚¹ã‚³ã‚¢", f"{avg_japanese:.2f}/5")
                
                with col3:
                    avg_logic = df['ãƒ­ã‚¸ãƒƒã‚¯ã‚¹ã‚³ã‚¢'].mean()
                    st.metric("å¹³å‡ãƒ­ã‚¸ãƒƒã‚¯ã‚¹ã‚³ã‚¢", f"{avg_logic:.2f}/5")
        
                with col4:
                    avg_total = df['ç·åˆã‚¹ã‚³ã‚¢'].mean()
                    st.metric("å¹³å‡ç·åˆã‚¹ã‚³ã‚¢", f"{avg_total:.2f}/15")
                
                # çµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                with st.expander("çµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", expanded=True):
                    st.dataframe(df[['id', 'è³ªå•', 'ãƒˆãƒ³ãƒãƒŠã‚¹ã‚³ã‚¢', 'æ—¥æœ¬èªã‚¹ã‚³ã‚¢', 'ãƒ­ã‚¸ãƒƒã‚¯ã‚¹ã‚³ã‚¢', 'ç·åˆã‚¹ã‚³ã‚¢', 'æ”¹å–„ç‚¹']].head(10))
                
                # CSVå‡ºåŠ›
                output_buffer = io.StringIO()
                df.to_csv(output_buffer, index=False, encoding='utf-8-sig')
                
                st.download_button(
                    label="ğŸ“¥ æ ¡æ­£çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=output_buffer.getvalue(),
                    file_name=f"mimiko_correction_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )