import streamlit as st
import json
import toml
import os
from pathlib import Path

# Google GenAI SDKã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import google.genai as genai
    from google.genai import types
    NEW_SDK = True
except ImportError:
    try:
        import google.generativeai as genai
        NEW_SDK = False
        st.warning("å¤ã„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚pip install google-genai ã§æ–°ã—ã„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«æ›´æ–°ã—ã¦ãã ã•ã„ã€‚")
    except ImportError:
        st.error("Google GenAI ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚pip install google-genai ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        st.stop()

# Vertex AIç”¨ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from google.auth import default
    from google.auth.transport.requests import Request
    from google.oauth2 import service_account
    VERTEX_AI_AVAILABLE = True
except ImportError:
    VERTEX_AI_AVAILABLE = False

# Load secrets
secrets_path = Path(__file__).parent / "secrets.toml"
if secrets_path.exists():
    secrets = toml.load(secrets_path)
    google_api_key = secrets.get("google_api_key", "")
    vertex_ai_project_id = secrets.get("vertex_ai_project_id", "")
    vertex_ai_location = secrets.get("vertex_ai_location", "us-central1")
    default_model = secrets.get("default_model", "gemini-2.0-flash-exp")
else:
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
    google_api_key = os.environ.get("GOOGLE_API_KEY", "")
    vertex_ai_project_id = os.environ.get("VERTEX_AI_PROJECT_ID", "")
    vertex_ai_location = os.environ.get("VERTEX_AI_LOCATION", "us-central1")
    default_model = os.environ.get("DEFAULT_MODEL", "gemini-2.0-flash-exp")

# AI ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚ªãƒ—ã‚·ãƒ§ãƒ³
default_model_options = [
    "gemini-2.0-flash-exp",
    "gemini-1.5-flash",
    "gemini-1.5-pro"
]

# Vertex AI ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚ªãƒ—ã‚·ãƒ§ãƒ³
vertex_model_options = [
    "gemini-2.0-flash-exp",
    "gemini-1.5-flash-002",
    "gemini-1.5-pro-002"
]

# Load correction prompts
def load_prompt(filename):
    prompt_path = Path(__file__).parent / filename
    with open(prompt_path, "r", encoding="utf-8") as f:
        return f.read()

# Load all prompts (ãƒ‘ã‚¿ãƒ¼ãƒ³é¡ä¼¼åº¦æ ¡æ­£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é™¤ã)
try:
    tonmana_prompt = load_prompt("ãƒˆãƒ³ãƒãƒŠæ ¡æ­£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ.txt")
    japanese_prompt = load_prompt("æ—¥æœ¬èªæ ¡æ­£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ.txt")
    logic_prompt = load_prompt("ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ.txt")
    comprehensive_prompt = load_prompt("ç·åˆæ ¡æ­£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ.txt")
except Exception as e:
    st.error(f"Error loading prompts: {e}")
    st.stop()

# Google AI/Vertex AIè¨­å®šé–¢æ•°
def setup_ai_provider(provider, model_name, api_key=None, project_id=None, location=None):
    """AI ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’è¨­å®šã™ã‚‹"""
    try:
        if provider == "Google AI":
            if NEW_SDK:
                client = genai.Client(api_key=api_key)
            else:
                genai.configure(api_key=api_key)
                client = None
            return client, model_name
        elif provider == "Vertex AI" and VERTEX_AI_AVAILABLE:
            if NEW_SDK:
                client = genai.Client(
                    vertexai=True,
                    project=project_id,
                    location=location
                )
            else:
                genai.configure(project=project_id, location=location)
                client = None
            return client, model_name
        else:
            st.error(f"ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ {provider} ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return None, None
    except Exception as e:
        st.error(f"AI ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®è¨­å®šã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None, None

# Function to call Gemini API
def call_gemini(prompt, user_message, provider, model_name, api_key=None, project_id=None, location=None):
    """Gemini APIã‚’å‘¼ã³å‡ºã™"""
    try:
        client, model = setup_ai_provider(provider, model_name, api_key, project_id, location)
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ§‹ç¯‰
        full_message = f"{prompt}\n\n{user_message}"
        
        if NEW_SDK:
            if client:
                response = client.models.generate_content(
                    model=model,
                    contents=full_message,
                    config=types.GenerateContentConfig(
                        max_output_tokens=1000,
                        temperature=0.1,
                    )
                )
                return response.text
            else:
                st.error("ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return None
        else:
            model_obj = genai.GenerativeModel(model)
            response = model_obj.generate_content(
                full_message,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=1000,
                    temperature=0.1,
                )
            )
            return response.text
            
    except Exception as e:
        st.error(f"Gemini APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# Function to parse JSON from Claude's response
def parse_json_response(response):
    try:
        # Find JSON in the response
        start_idx = response.find('{')
        end_idx = response.rfind('}') + 1
        if start_idx >= 0 and end_idx > start_idx:
            json_str = response[start_idx:end_idx]
            return json.loads(json_str)
        else:
            st.warning("Could not find JSON in the response")
            return None
    except Exception as e:
        st.error(f"Error parsing JSON: {e}")
        st.code(response)  # Display the raw response for debugging
        return None

# Main app
st.title("mimikoæ ¡æ­£ã‚·ã‚¹ãƒ†ãƒ ")

# Initialize variables with default values
api_key_input = google_api_key
project_id_input = vertex_ai_project_id
location_input = vertex_ai_location

# Settings section
with st.expander("âš™ï¸ è¨­å®š", expanded=False):
    col1, col2 = st.columns(2)
    
    with col1:
        # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼é¸æŠ
        ai_provider = st.selectbox(
            "ğŸ¤– AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼",
            ["Google AI", "Vertex AI"] if VERTEX_AI_AVAILABLE else ["Google AI"],
            key="ai_provider"
        )
        
        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        if ai_provider == "Google AI":
            available_models = default_model_options
        else:
            available_models = vertex_model_options
            
        selected_model = st.selectbox(
            "ğŸ¯ ãƒ¢ãƒ‡ãƒ«",
            available_models,
            index=0 if default_model not in available_models else available_models.index(default_model),
            key="selected_model"
        )
    
    with col2:
        if ai_provider == "Google AI":
            api_key_input = st.text_input(
                "ğŸ”‘ Google API Key",
                value=google_api_key,
                type="password",
                help="Google AI Studio ã§å–å¾—ã—ãŸAPIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
            )
        else:
            project_id_input = st.text_input(
                "ğŸ“ Project ID",
                value=vertex_ai_project_id,
                help="Google Cloud ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
            )
            location_input = st.text_input(
                "ğŸŒ Location",
                value=vertex_ai_location,
                help="Vertex AI ã®ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æŒ‡å®šã—ã¦ãã ã•ã„"
            )

# Input section
st.header("å…¥åŠ›")
user_question = st.text_area("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•", height=100)

# ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚«ãƒ†ã‚´ãƒªé¸æŠï¼ˆæœ€å¤§4ã¤ã¾ã§ï¼‰
st.subheader("ä½¿ç”¨ã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚«ãƒ†ã‚´ãƒª")
col1, col2 = st.columns(2)

with col1:
    category1 = st.selectbox("ã‚«ãƒ†ã‚´ãƒª1", ["ãªã—", "ãƒã‚¦ã‚¹", "ã‚µã‚¤ãƒ³", "å¤©ä½“", "ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆ", "MPè»¸", "ã‚¿ãƒ­ãƒƒãƒˆ"], key="cat1")
    if category1 != "ãªã—":
        keyword1 = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", placeholder="ä¾‹: ç¬¬1ãƒã‚¦ã‚¹", key="kw1")
    else:
        keyword1 = ""

with col2:
    category2 = st.selectbox("ã‚«ãƒ†ã‚´ãƒª2", ["ãªã—", "ãƒã‚¦ã‚¹", "ã‚µã‚¤ãƒ³", "å¤©ä½“", "ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆ", "MPè»¸", "ã‚¿ãƒ­ãƒƒãƒˆ"], key="cat2")
    if category2 != "ãªã—":
        keyword2 = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2", placeholder="ä¾‹: ç‰¡ç¾Šåº§", key="kw2")
    else:
        keyword2 = ""

col3, col4 = st.columns(2)

with col3:
    category3 = st.selectbox("ã‚«ãƒ†ã‚´ãƒª3", ["ãªã—", "ãƒã‚¦ã‚¹", "ã‚µã‚¤ãƒ³", "å¤©ä½“", "ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆ", "MPè»¸", "ã‚¿ãƒ­ãƒƒãƒˆ"], key="cat3")
    if category3 != "ãªã—":
        keyword3 = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰3", placeholder="ä¾‹: å¤ªé™½", key="kw3")
    else:
        keyword3 = ""

with col4:
    category4 = st.selectbox("ã‚«ãƒ†ã‚´ãƒª4", ["ãªã—", "ãƒã‚¦ã‚¹", "ã‚µã‚¤ãƒ³", "å¤©ä½“", "ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆ", "MPè»¸", "ã‚¿ãƒ­ãƒƒãƒˆ"], key="cat4")
    if category4 != "ãªã—":
        keyword4 = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰4", placeholder="ä¾‹: ç«", key="kw4")
    else:
        keyword4 = ""

ai_answer = st.text_area("AIå ã„å¸«ã®å›ç­”", height=150)

# Initialize session state
if 'corrections' not in st.session_state:
    st.session_state.corrections = {}
if 'tonmana_problems' not in st.session_state:
    st.session_state.tonmana_problems = []
if 'japanese_improvements' not in st.session_state:
    st.session_state.japanese_improvements = []
if 'logic_improvements' not in st.session_state:
    st.session_state.logic_improvements = []
if 'correction_done' not in st.session_state:
    st.session_state.correction_done = False
if 'user_input' not in st.session_state:
    st.session_state.user_input = {"question": "", "keywords": [], "answer": ""}

# Process button
if st.button("æ ¡æ­£ã‚’å®Ÿè¡Œ") or st.session_state.correction_done:
    if not user_question or not ai_answer:
        st.error("è³ªå•ã¨å›ç­”ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    else:
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æƒ…å ±ã®æ•´ç†
        keywords = []
        if category1 != "ãªã—" and keyword1:
            keywords.append(f"{category1}: {keyword1}")
        if category2 != "ãªã—" and keyword2:
            keywords.append(f"{category2}: {keyword2}")
        if category3 != "ãªã—" and keyword3:
            keywords.append(f"{category3}: {keyword3}")
        if category4 != "ãªã—" and keyword4:
            keywords.append(f"{category4}: {keyword4}")
        
        # Save user input to session state
        st.session_state.user_input = {
            "question": user_question,
            "keywords": keywords,
            "answer": ai_answer
        }
        
        # Set correction_done flag to true
        st.session_state.correction_done = True
        
        # è¨­å®šã®æº–å‚™
        if ai_provider == "Google AI":
            current_api_key = api_key_input
            current_project_id = None
            current_location = None
        else:
            current_api_key = None
            current_project_id = project_id_input
            current_location = location_input

        # Only call APIs if not already done
        if 'tonmana_result' not in st.session_state:
            with st.spinner("ãƒˆãƒ³ãƒãƒŠæ ¡æ­£ä¸­..."):
                # 1. ãƒˆãƒ³ãƒãƒŠæ ¡æ­£
                tonmana_message = f"""##QUESTION##
{user_question}

##KEYWORDS##
{', '.join(keywords) if keywords else 'ãªã—'}

##ANSWER_CAND##
{ai_answer}
"""
                tonmana_result = call_gemini(
                    tonmana_prompt, 
                    tonmana_message,
                    ai_provider,
                    selected_model,
                    current_api_key,
                    current_project_id,
                    current_location
                )
                if tonmana_result:
                    tonmana_json = parse_json_response(tonmana_result)
                    if tonmana_json:
                        st.session_state.tonmana_result = tonmana_result
                        st.session_state.tonmana_json = tonmana_json
                        
                        # Store in session state
                        st.session_state.corrections["tonmana"] = {
                            "score": tonmana_json.get('style_score', 'N/A'),
                            "comment": tonmana_json.get('comment', 'N/A'),
                            "problems": tonmana_json.get('problems', [])
                        }
        
        if 'japanese_result' not in st.session_state:
            with st.spinner("æ—¥æœ¬èªæ ¡æ­£ä¸­..."):
                # 2. æ—¥æœ¬èªæ ¡æ­£
                japanese_message = ai_answer
                japanese_result = call_gemini(
                    japanese_prompt,
                    japanese_message,
                    ai_provider,
                    selected_model,
                    current_api_key,
                    current_project_id,
                    current_location
                )
                if japanese_result:
                    japanese_json = parse_json_response(japanese_result)
                    if japanese_json:
                        st.session_state.japanese_result = japanese_result
                        st.session_state.japanese_json = japanese_json
                        
                        # Store in session state
                        st.session_state.corrections["japanese"] = {
                            "score": japanese_json.get('score', 'N/A'),
                            "improvements": japanese_json.get('improvements', [])
                        }
        
        if 'logic_result' not in st.session_state and logic_prompt.strip():
            with st.spinner("ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£ä¸­..."):
                # 3. ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£
                logic_message = f"""è³ªå•: {user_question}
ä½¿ç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(keywords) if keywords else 'ãªã—'}
å›ç­”: {ai_answer}
"""
                logic_result = call_gemini(
                    logic_prompt,
                    logic_message,
                    ai_provider,
                    selected_model,
                    current_api_key,
                    current_project_id,
                    current_location
                )
                if logic_result:
                    logic_json = parse_json_response(logic_result)
                    if logic_json:
                        st.session_state.logic_result = logic_result
                        st.session_state.logic_json = logic_json
                        
                        # Store in session state
                        st.session_state.corrections["logic"] = {
                            "score": logic_json.get('score', 'N/A'),
                            "improvements": logic_json.get('improvements', [])
                        }
        
        # Calculate total score
        total_score = 0
        max_score = 15
        valid_scores = 0
        
        for correction_type in ["tonmana", "japanese", "logic"]:
            if correction_type in st.session_state.corrections:
                score = st.session_state.corrections[correction_type]["score"]
                if isinstance(score, (int, float)) and score != 'N/A':
                    total_score += score
                    valid_scores += 1
        
        # Display total score
        if valid_scores > 0:
            st.header(f"ç·åˆã‚¹ã‚³ã‚¢: {total_score}/{max_score}ç‚¹")
        
        # Display results
        # 1. ãƒˆãƒ³ãƒãƒŠæ ¡æ­£çµæœ
        if 'tonmana_json' in st.session_state:
            st.subheader("ãƒˆãƒ³ãƒãƒŠæ ¡æ­£çµæœ")
            tonmana_json = st.session_state.tonmana_json
            st.write(f"ã‚¹ã‚³ã‚¢: {tonmana_json.get('style_score', 'N/A')}/5")
            st.write(f"ã‚³ãƒ¡ãƒ³ãƒˆ: {tonmana_json.get('comment', 'N/A')}")
            
            problems = tonmana_json.get('problems', [])
            if problems:
                st.write("æ”¹å–„ç‚¹:")
                for i, problem in enumerate(problems):
                    # Create a unique key for each checkbox
                    checkbox_key = f"tonmana_cb_{i}"
                    
                    # Check if the problem is in the selected problems list
                    is_selected = problem in st.session_state.tonmana_problems
                    
                    # Display checkbox
                    checked = st.checkbox(problem, key=checkbox_key, value=is_selected)
                    
                    # Update selected problems list based on checkbox state
                    if checked and problem not in st.session_state.tonmana_problems:
                        st.session_state.tonmana_problems.append(problem)
                    elif not checked and problem in st.session_state.tonmana_problems:
                        st.session_state.tonmana_problems.remove(problem)
            else:
                st.write("æ”¹å–„ç‚¹ã¯ã‚ã‚Šã¾ã›ã‚“")
        
        # 2. æ—¥æœ¬èªæ ¡æ­£çµæœ
        if 'japanese_json' in st.session_state:
            st.subheader("æ—¥æœ¬èªæ ¡æ­£çµæœ")
            japanese_json = st.session_state.japanese_json
            st.write(f"ã‚¹ã‚³ã‚¢: {japanese_json.get('score', 'N/A')}/5")
            
            improvements = japanese_json.get('improvements', [])
            if improvements:
                st.write("æ”¹å–„ç‚¹:")
                for i, improvement in enumerate(improvements):
                    # Create a unique key for each checkbox
                    checkbox_key = f"japanese_cb_{i}"
                    
                    # Check if the improvement is in the selected improvements list
                    is_selected = improvement in st.session_state.japanese_improvements
                    
                    # Display checkbox
                    checked = st.checkbox(improvement, key=checkbox_key, value=is_selected)
                    
                    # Update selected improvements list based on checkbox state
                    if checked and improvement not in st.session_state.japanese_improvements:
                        st.session_state.japanese_improvements.append(improvement)
                    elif not checked and improvement in st.session_state.japanese_improvements:
                        st.session_state.japanese_improvements.remove(improvement)
            else:
                st.write("æ”¹å–„ç‚¹ã¯ã‚ã‚Šã¾ã›ã‚“")
        
        # 3. ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£çµæœ
        if 'logic_json' in st.session_state:
            st.subheader("ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£çµæœ")
            logic_json = st.session_state.logic_json
            st.write(f"ã‚¹ã‚³ã‚¢: {logic_json.get('score', 'N/A')}/5")
            
            improvements = logic_json.get('improvements', [])
            if improvements:
                st.write("æ”¹å–„ç‚¹:")
                for i, improvement in enumerate(improvements):
                    # Create a unique key for each checkbox
                    checkbox_key = f"logic_cb_{i}"
                    
                    # Check if the improvement is in the selected improvements list
                    is_selected = improvement in st.session_state.logic_improvements
                    
                    # Display checkbox
                    checked = st.checkbox(improvement, key=checkbox_key, value=is_selected)
                    
                    # Update selected improvements list based on checkbox state
                    if checked and improvement not in st.session_state.logic_improvements:
                        st.session_state.logic_improvements.append(improvement)
                    elif not checked and improvement in st.session_state.logic_improvements:
                        st.session_state.logic_improvements.remove(improvement)
            else:
                st.write("æ”¹å–„ç‚¹ã¯ã‚ã‚Šã¾ã›ã‚“")
        elif logic_prompt.strip():
            st.warning("ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒç©ºã§ã™ã€‚ã“ã®æ ¡æ­£ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")
        
        # Show button to proceed to comprehensive correction
        st.session_state.show_comprehensive_button = True

# Reset button
if st.button("ãƒªã‚»ãƒƒãƒˆ"):
    # Clear session state
    for key in list(st.session_state.keys()):
        del st.session_state[key]
    # Rerun the app
    st.rerun()

# Comprehensive correction button
if st.session_state.get("show_comprehensive_button", False):
    st.header("ç·åˆæ ¡æ­£")
    if st.button("é¸æŠã—ãŸæ”¹å–„ç‚¹ã§ç·åˆæ ¡æ­£ã‚’å®Ÿè¡Œ") or 'comprehensive_result' in st.session_state:
        if 'comprehensive_result' not in st.session_state:
            with st.spinner("ç·åˆæ ¡æ­£ä¸­..."):
                # è¨­å®šã®æº–å‚™ï¼ˆcomprehensive correctionç”¨ï¼‰
                if ai_provider == "Google AI":
                    current_api_key = api_key_input
                    current_project_id = None
                    current_location = None
                else:
                    current_api_key = None
                    current_project_id = project_id_input
                    current_location = location_input
                # Prepare selected improvements
                selected_improvements = {
                    "ãƒˆãƒ³ãƒãƒŠæ ¡æ­£": st.session_state.get("tonmana_problems", []),
                    "æ—¥æœ¬èªæ ¡æ­£": st.session_state.get("japanese_improvements", []),
                    "ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£": st.session_state.get("logic_improvements", [])
                }
                
                # Prepare scores
                scores = {}
                if "tonmana" in st.session_state.corrections:
                    scores["ãƒˆãƒ³ãƒãƒŠæ ¡æ­£"] = st.session_state.corrections["tonmana"]["score"]
                if "japanese" in st.session_state.corrections:
                    scores["æ—¥æœ¬èªæ ¡æ­£"] = st.session_state.corrections["japanese"]["score"]
                if "logic" in st.session_state.corrections:
                    scores["ãƒ­ã‚¸ãƒƒã‚¯æ ¡æ­£"] = st.session_state.corrections["logic"]["score"]
                
                # Create message for comprehensive correction
                comprehensive_message = f"""AIå ã„å¸«ã®å›ç­”:
{st.session_state.user_input["answer"]}

ä½¿ç”¨ã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:
{', '.join(st.session_state.user_input["keywords"]) if st.session_state.user_input["keywords"] else 'ãªã—'}

å„æ ¡æ­£AIã®æ¡ç‚¹çµæœ:
"""
                for correction_type, score in scores.items():
                    comprehensive_message += f"{correction_type}: {score}/5\n"
                
                comprehensive_message += "\né¸æŠã•ã‚ŒãŸæ”¹å–„ç‚¹:\n"
                for correction_type, improvements in selected_improvements.items():
                    if improvements:
                        comprehensive_message += f"\n{correction_type}:\n"
                        for i, improvement in enumerate(improvements):
                            comprehensive_message += f"{i+1}. {improvement}\n"
                
                # Call Gemini for comprehensive correction
                comprehensive_result = call_gemini(
                    comprehensive_prompt,
                    comprehensive_message,
                    ai_provider,
                    selected_model,
                    current_api_key,
                    current_project_id,
                    current_location
                )
                if comprehensive_result:
                    # Save the result to session state
                    st.session_state.comprehensive_result = comprehensive_result
        
        # Display comprehensive correction result
        if 'comprehensive_result' in st.session_state:
            st.subheader("ç·åˆæ ¡æ­£çµæœ")
            st.write(st.session_state.comprehensive_result)